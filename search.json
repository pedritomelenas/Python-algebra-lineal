[
  {
    "objectID": "ALME-espacios-vectoriales.html",
    "href": "ALME-espacios-vectoriales.html",
    "title": "Espacios vectoriales",
    "section": "",
    "text": "En este documento ilustraremos cómo usar Python para resolver los problemas tipo propuestos por L. Merino y E. Santos en página de resolución de ejercicios tipo correspondientes al bloque “Espacios Vectoriales”.",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#coordenadas.-dependencia-lineal",
    "href": "ALME-espacios-vectoriales.html#coordenadas.-dependencia-lineal",
    "title": "Espacios vectoriales",
    "section": "Coordenadas. Dependencia lineal",
    "text": "Coordenadas. Dependencia lineal\n\nEjercicio\nSe considera en el espacio vectorial \\({\\mathbb{R}}^3\\) la base \\(B=\\{(1,0,1), (0,2,0) , (0,0,3)\\}\\). Determinar el vector \\(x\\) cuyas cordenadas respecto de \\(B\\) son \\(x=(2,1,2)_{B}\\).\nNuestro vector tiene coordenadas \\((2,1,2)_B\\), por lo que \\(x=2\\times(1,0,1)+1\\times(0,2,0)+2\\times (0,0,3)\\). Ponemos por tanto los vectores de \\(B\\) como columnas en un matriz y multiplicamos por el vector \\((2,1,2)\\).\n\nfrom sympy import Matrix\n\n\nB=Matrix([(1,0,1),(0,2,0),(0,0,3)]).T\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 2 & 0\\\\1 & 0 & 3\\end{matrix}\\right]\\)\n\n\n\nB*Matrix([2,1,2])\n\n\\(\\displaystyle \\left[\\begin{matrix}2\\\\2\\\\8\\end{matrix}\\right]\\)\n\n\nCon lo que nuestro vector es \\((2,2,8)\\).\n\n\nEjercicio\nSe considera en el espacio vectorial \\({\\mathbb{R}}^3\\) la base \\(B=\\{(1,0,1), (0,2,0) , (0,0,3)\\}\\). Determinar coordenadas respecto de \\(B\\) del vector \\(x=(5,4,2)\\).\nTenemos que encontrar \\(a,b,c\\in \\mathbb{R}\\) tales que \\((5,4,2)=a(1,0,1)+b(0,2,0)+c(0,0,3)\\), y esto equivale a resolver el sistema\n\\[\n\\left\\{\n\\begin{array}{rcl}\na&=&5,\\\\\n2b&=&4,\\\\\na+3c&=&2.\n\\end{array}\n\\right.\n\\]\nAprovechamos que ya tenemos definida la matriz \\(B\\) del ejercicio anterior.\n\nfrom sympy import linsolve\n\n\nlinsolve((B,Matrix([5,4,2])))\n\n\\(\\displaystyle \\left\\{\\left( 5, \\  2, \\  -1\\right)\\right\\}\\)\n\n\nPor lo que \\(x=(5,2,-1)_B\\).\n\nB.inv()*Matrix([5,4,2])\n\n\\(\\displaystyle \\left[\\begin{matrix}5\\\\2\\\\-1\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nEn el espacio vectorial \\(\\mathcal{P}_3(\\mathbb{R})\\) se consideran los vectores \\(p(x) = x^3+x^2+x+1\\), \\(q(x)= 2x^2+1\\) y \\(r(x)= x^3+2x^2\\). Estudiar si son linealmente dependientes o independientes.\nConsideramos la base estándar de \\(\\mathcal{P}_3(\\mathbb{R})\\), \\(B=\\{1,x,x^2, x^3 \\}\\). Respecto de esta base, las coordenadas de los vectores que nos dan son: \\[p(x)=(1,1,1,1)_B,  q(x)=(1,0,2,0)_B, r(x)=(0,0,2,1)_B.\\] De esta forma, si ponemos esos vectores en una matriz y vemos su forma reducida por filas, podremos ver si son linealmente dependientes o no. Para ello haremos uso de rref.\n\nA=Matrix([(1,1,1,1),(1,0,2,0),(0,0,2,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & 1\\\\1 & 0 & 2 & 0\\\\0 & 0 & 2 & 1\\end{matrix}\\right]\\)\n\n\n\nA.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & -1\\\\0 & 1 & 0 & \\frac{3}{2}\\\\0 & 0 & 1 & \\frac{1}{2}\\end{matrix}\\right]\\)\n\n\nVemos que la matriz tiene rango máximo, por lo que los vectores del enunciado son linealmente independientes.\n\n\nEjercicio\nEn el espacio vectorial \\({\\mathfrak M}_2(\\mathbb{R})\\) se consideran los vectores \\(a=\\begin{pmatrix} 1  & 2 \\\\ 2 & 1 \\end{pmatrix}\\), \\(b=\\begin{pmatrix} 1  & 1 \\\\ 2 & 0 \\end{pmatrix}\\), \\(c=\\begin{pmatrix} 0  & 1 \\\\ 2 & 1 \\end{pmatrix}\\) y \\(b=\\begin{pmatrix} 1  & 2 \\\\ 3 & 1 \\end{pmatrix}\\). Estudiar si son linealmente dependientes o independientes.\nConsideramos la base estándar de \\({\\mathfrak M}_2(\\mathbb{R})\\), \\(B=\\left\\{\n\\begin{pmatrix} 1  & 0 \\\\ 0 & 0 \\end{pmatrix},\n\\begin{pmatrix} 0  & 1 \\\\ 0 & 0 \\end{pmatrix},\n\\begin{pmatrix} 0  & 0 \\\\ 1 & 0 \\end{pmatrix},\n\\begin{pmatrix} 0  & 0 \\\\ 0 & 1 \\end{pmatrix}\n\\right\\}\\). Respecto de esta base los vectores dados tienen coordenadas \\((1,2,2,1)_B\\), \\((1,1,2,0)_B\\), \\((0,1,2,1)_B\\) y \\((1,2,3,1)_B\\), respectivamente. Procedemos como antes poniendo esos vectores por filas en una matriz y calculamos su forma reducida por filas.\n\nA=Matrix([(1,2,2,1),(1,1,2,0),(0,1,2,1),(1,2,3,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 2 & 1\\\\1 & 1 & 2 & 0\\\\0 & 1 & 2 & 1\\\\1 & 2 & 3 & 1\\end{matrix}\\right]\\)\n\n\n\nA.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & -1\\\\0 & 1 & 0 & 1\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nComo podemos observar, hay una fila de ceros, por lo que a lo sumo tres de ellos son linealmente independientes, y los cuatro son linealmente dependientes.\n\nfrom sympy import eye\n\n\nAI=A.row_join(eye(4))\nrAI=AI.rref(pivots=False)\nrAI\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & -1 & 0 & 1 & -1 & 0\\\\0 & 1 & 0 & 1 & 0 & -2 & -1 & 2\\\\0 & 0 & 1 & 0 & 0 & 1 & 1 & -1\\\\0 & 0 & 0 & 0 & 1 & 1 & 1 & -2\\end{matrix}\\right]\\)\n\n\n\nQ=rAI[:,4:]\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 1 & -1 & 0\\\\0 & -2 & -1 & 2\\\\0 & 1 & 1 & -1\\\\1 & 1 & 1 & -2\\end{matrix}\\right]\\)\n\n\n\nQ*A\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & -1\\\\0 & 1 & 0 & 1\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nAl ser la última fila todo ceros, ya tenemos la relación de dependencia lineal.\n\nQ[3,:]*A\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nPor lo que \\(a+b+c-2d=0\\).",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#cambio-de-base",
    "href": "ALME-espacios-vectoriales.html#cambio-de-base",
    "title": "Espacios vectoriales",
    "section": "Cambio de base",
    "text": "Cambio de base\n\nEjercicio\nEn el espacio vectorial \\(\\mathcal{P}_3(\\mathbb{R})\\) de los polinomios de grado menor o igual que \\(3\\), se consideran las bases estándar \\(B=\\{1,x,x^2, x^3 \\}\\) y \\(B'=\\{x^3+x^2+x+1, x^3+x^2+x, x^3+x^2, x^3\\}\\). Determinar la ecuación del cambio de base de \\(B\\) a \\(B'\\) y las coordenadas respecto de \\(B'\\) del vector \\(p(x)=x^3+2x\\).\nTenemos que los vectores de \\(B'\\) tienen coordenadas \\[\n\\begin{array}{lcl}\nx^3+x^2+x+1 &= & (1,1,1,1)_B, \\\\\nx^3+x^2+x   &= & (0,1,1,1)_B, \\\\\nx^3+x^2     &= & (0,0,1,1)_B, \\\\\nx^3         &= & (0,0,0,1)_B.\n\\end{array}\n\\]\nPor lo que la matriz de cambio de base de \\(B'\\) a \\(B\\) es \\[\nP=\n\\begin{pmatrix}\n1 & 0 & 0 & 0 \\\\\n1 & 1 & 0 & 0 \\\\\n1 & 1 & 1 & 0 \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix}.\n\\] Y la de \\(B\\) a \\(B'\\) será su inversa.\n\nP=Matrix([(1,1,1,1),(0,1,1,1),(0,0,1,1),(0,0,0,1)]).T\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\1 & 1 & 0 & 0\\\\1 & 1 & 1 & 0\\\\1 & 1 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nP.inv()\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\-1 & 1 & 0 & 0\\\\0 & -1 & 1 & 0\\\\0 & 0 & -1 & 1\\end{matrix}\\right]\\)\n\n\nEl polinomio \\(p(x)\\) tiene coordenadas \\((0,2,0,1)_B\\), por lo que sus coordenadas respecto de \\(B'\\) son\n\nP.inv()*Matrix([0,2,0,1])\n\n\\(\\displaystyle \\left[\\begin{matrix}0\\\\2\\\\-2\\\\1\\end{matrix}\\right]\\)\n\n\nesto es, \\(p(x)=(0,2,-2,1)_{B'}\\)\n\n\nEjercicio\nEn el espacio vectorial \\(\\mathbb{R}^3\\) se consideran las bases \\(B'=\\{ (1,1,0), (0,1,2),  (1,0,1) \\}\\) y \\(B''=\\{(1,0,0), (2,1,0), (1,1,1)\\}\\). Determinar la ecuación del cambio de base de \\(B'\\) a \\(B''\\).\nVamos a determinar la matriz de cambio de base \\(P\\) de \\(B'\\) a la base estándar \\(B\\), y luego la de \\(B\\) a \\(B''\\), \\(Q\\). Multiplicando \\(Q\\) y \\(P\\), tendremos la matriz de cambio de base de \\(B'\\) a \\(B''\\).\n\nP=Matrix([(1,1,0),(0,1,2),(1,0,1)]).T\nQ=Matrix([(1,0,0),(2,1,0),(1,1,1)]).T.inv()\n\n\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 1\\\\1 & 1 & 0\\\\0 & 2 & 1\\end{matrix}\\right]\\)\n\n\n\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -2 & 1\\\\0 & 1 & -1\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nQ*P\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 2\\\\1 & -1 & -1\\\\0 & 2 & 1\\end{matrix}\\right]\\)",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#espresiones-de-un-subespacio",
    "href": "ALME-espacios-vectoriales.html#espresiones-de-un-subespacio",
    "title": "Espacios vectoriales",
    "section": "Espresiones de un subespacio",
    "text": "Espresiones de un subespacio\n\nEjercicio\nEn el espacio vectorial \\(\\mathcal{P}_3(\\mathbb{K})\\) de los polinomios de grado menor o igual que \\(3\\), se considera el subespacio \\(U\\) generado por \\(2x^3+2x+1, 2x^3+x^2+3x+1, x^3+x^2+2x, 2x^2+2x+1\\). Determinar una base de \\(U\\), unas ecuaciones paramétricas y unas cartesianas.\nConsideramos la base estándar \\(B=\\{1,x,x^2,x^3\\}\\) de \\(\\mathcal{P}_3(\\mathbb{K})\\), entonces \\[\n\\begin{array}{rcl}\n2x^3+2x+1    & = & (1,2,0,2)_B, \\\\\n2x^3+x^2+3x+1 & = & (1,3,1,2)_B, \\\\\nx^3+x^2+2x    & = & (0,2,1,1)_B, \\\\\n2x^2+2x+1     & = & (1,2,2,0)_B.\n\\end{array}\n\\] Para encontrar una base, calculamos la forma normal reducida de la matriz cuyas filas son esas coordenadas.\n\nA=Matrix([(1,2,0,2),(1,3,1,2),(0,2,1,1),(1,2,2,0)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 2\\\\1 & 3 & 1 & 2\\\\0 & 2 & 1 & 1\\\\1 & 2 & 2 & 0\\end{matrix}\\right]\\)\n\n\n\nrA=A.rref(pivots=False)\nrA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\0 & 1 & 0 & 1\\\\0 & 0 & 1 & -1\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nPor lo que una base de \\(U\\) es \\(\\{(1,0,0,0),(0,1,0,1),(0,0,1,-1)\\}\\). Las ecuaciones paramétricas serán \\[\n\\left\\{ \\begin{array}{rcl}\nx_1 &=& \\lambda,     \\\\\nx_2 &=& \\mu,  \\\\\nx_3 &=& \\gamma, \\\\\nx_4  &=&  \\mu - \\gamma.\n\\end{array} \\right.\n\\]\nPara encontrar las ecuaciones implícitas, vamos a colocar los vectores de la base que hemos elegido de \\(U\\) por columnas.\n\nU=rA[0:3,:].T\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nLe añadimos la identidad.\n\nUI=U.row_join(eye(4))\nUI    \n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0 & 0 & 1 & 0\\\\0 & 1 & -1 & 0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nEliminar parámetros (tres primeras columnas) se corresponde con encontrar la forma reducida por filas, y ver en qué filas dejan de haber parámetros.\n\nUI.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0 & 0 & 1 & 1\\\\0 & 0 & 1 & 0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0 & 1 & -1 & -1\\end{matrix}\\right]\\)\n\n\nDe la última fila se deduce que una ecuación implícita de \\(U\\) es \\(x_2-x_3-x_4=0\\).\n\nfrom sympy import symbols\n\n\nx,y,z,t=symbols(\"x y z t\")\n\n\nUX=U.row_join(Matrix([x,y,z,t]))\nUX\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & x\\\\0 & 1 & 0 & y\\\\0 & 0 & 1 & z\\\\0 & 1 & -1 & t\\end{matrix}\\right]\\)\n\n\nsympy no considera las variables como parámetros sujetos a condiciones, por lo que si calculamos la forma escalonada reducida por filas nos dará la identidad.\n\nUX.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nPodemos hacer la reducción a mano.\n\nUX[3,:]=UX[3,:]-UX[1,:]\nUX\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & x\\\\0 & 1 & 0 & y\\\\0 & 0 & 1 & z\\\\0 & 0 & -1 & t - y\\end{matrix}\\right]\\)\n\n\n\nUX[3,:]=UX[3,:]+UX[2,:]\nUX\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & x\\\\0 & 1 & 0 & y\\\\0 & 0 & 1 & z\\\\0 & 0 & 0 & t - y + z\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nEn \\(\\mathfrak{M}_2(\\mathbb{R})\\) se considera el subespacio \\(U\\) que tiene ecuaciones cartesianas respecto de la base estándar \\[\n\\left\\{ \\begin{array}{rcl}\nx+y+t&=& 0, \\\\\n2x-y+t&=& 0.\n\\end{array} \\right.\n\\] Determinar una base de \\(U\\).\n\nA=Matrix([(1,1,0,1),(2,-1,0,1)])\n\n\nA.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & \\frac{2}{3}\\\\0 & 1 & 0 & \\frac{1}{3}\\end{matrix}\\right]\\)\n\n\nPor lo que nuestro sistema original es equivalente a \\[\n\\left\\{ \\begin{array}{rcl}\nx+\\frac{2}{3} t&=& 0, \\\\\ny+\\frac{1}{3}t&=& 0.\n\\end{array} \\right.\n\\]\nTomando como parámetros \\(z\\) y \\(t\\), y pasando a paramétricas obtenemos que una base de \\(U\\) es \\(\\{(0,0,1,0)_B, (-2/3,-1/3,0,1)_B\\}\\), esto es, \\[\n\\left\\{\\begin{pmatrix}\n-\\frac{2}{3} & -\\frac{1}{3} \\\\\n0 & 1\n\\end{pmatrix}\n,\n\\;\n\\begin{pmatrix}\n0 & 0 \\\\\n1 & 0\n\\end{pmatrix}\n\\right\\}.\n\\]\nEsto también lo podemos obtener calculando la forma reducida por filas de la traspuesta de \\(A\\) añadiéndole la identidad.\n\nrtA=A.col_join(eye(4)).T.rref(pivots=False)\nrtA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & \\frac{1}{2} & 0 & \\frac{1}{2}\\\\0 & 1 & 0 & - \\frac{1}{2} & 0 & \\frac{1}{2}\\\\0 & 0 & 1 & \\frac{1}{2} & 0 & - \\frac{3}{2}\\\\0 & 0 & 0 & 0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nLa matriz de paso es\n\nQ=rtA[:,2:]\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & \\frac{1}{2} & 0 & \\frac{1}{2}\\\\0 & - \\frac{1}{2} & 0 & \\frac{1}{2}\\\\1 & \\frac{1}{2} & 0 & - \\frac{3}{2}\\\\0 & 0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nAl ser las dos últimas filas de la forma reducida de t(A) cero, esto nos dice que las dos últimas filas de \\(Q\\) son una base para \\(U\\), pues son linealmente independientes y verifican las ecuaciones de \\(U\\).\n\nQ[2:4,:]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & 0 & - \\frac{3}{2}\\\\0 & 0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nLo que nos dice que otra posible base es \\(\\{(0,0,1,0)_B,(1,1/2,0,-3/2)_B\\}\\) (nótese que el último vector es \\(-2/3\\) por el segundo vector que obtuvimos antes).",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#paso-de-generadores-a-implícitas-y-viceversa",
    "href": "ALME-espacios-vectoriales.html#paso-de-generadores-a-implícitas-y-viceversa",
    "title": "Espacios vectoriales",
    "section": "Paso de generadores a implícitas y viceversa",
    "text": "Paso de generadores a implícitas y viceversa\nVamos a escribir una función que nos permita calcular las ecuaciones implícitas de un subespacio vectorial a partir de un sistema de generadores de dicho subespacio, y viceversa.\nSupongamos que nuestro subespacio vectorial \\(U\\subseteq \\mathbb{R}^n\\) está generado por \\(\\{v_1,\\dots,v_k\\}\\). Supongamos que la dimensión de \\(U\\) es \\(d\\), que además coincide con el rango de la matriz \\(A\\) cuyas columnas son \\(v_1,\\dots, v_k\\). Supongamos que \\(H\\) es la forma normal reducida por columnas de \\(A\\), y que \\(Q\\) es tal que \\(Q A=H\\). Tenemos entonces que las últimas \\(n-d\\) columnas de \\(H\\) son cero. Esto quiere decir que las últimas \\(d-n\\) filas de \\(Q\\) cuando las multiplicamos por \\(A\\) dan cero, o dicho de otra forma, esas últimas \\(d-n\\) filas son los coeficientes de ecuaciones que verifican todos los generadores de \\(U\\), y por tanto son unas ecuaciones implícitas de \\(U\\).\nSi, en lugar de generadores, partimos de \\(k\\) ecuaciones implícitas de \\(U\\), el proceso es dual, por lo que si en \\(A\\) almacenamos (por filas) los coeficientes de dichas ecuaciones y tomamos su transpuesta, podemos calcular nuevamente la forma normal de hermite de \\(A^t\\), \\(H\\), y \\(Q\\) tal que \\(QA^t=H\\). Si de esas \\(k\\) ecuaciones, \\(d\\) de ellas son independientes, entonces las últimas \\(n-d\\) columnas de \\(H\\) serán nulas. De esta forma las últimas \\(n-d\\) filas de \\(Q\\) conforman una base de \\(U\\).\nEscribamos este proceso en python.\n\ndef gensec(A):\n    \"\"\"\n    A es una matriz cuyas filas son los generadores o los coeficientes del subespacio\n    La salida son las ecuaciones implícitas o los generadores (por filas)\n    \"\"\"\n    c=A.cols # número de columnas de A\n    f=A.rows # número de filas\n    r=A.rank() # rango\n    rtAI=A.T.row_join(eye(c)).rref(pivots=False) # añadimos la identidad calculamor forma reducida por columnas\n    ecs=rtAI[r:,f:]# nos quedamos con la parte que corresponde a ceros (ecuaciones o generadores según la entrada)\n    return ecs\n\nTenemos que tener presente al usar esta función que estamos escribiendo los generadores del subespacio por filas en la matriz de entrada; y si la entrada son ecuaciones, los coeficientes también van por filas.\nVeamos su uso con los dos ejemplos de antes.\n\nEjemplo 1\nSea \\(U=\\mathcal{L}(\\{(1,2,0,2),(1,3,1,2),(0,2,1,1),(1,2,2,0) \\})\\subseteq\\mathbb{R}^4\\). Calculemos sus ecuaciones implícitas.\n\nA=Matrix([(1,2,0,2),(1,3,1,2),(0,2,1,1),(1,2,2,0)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 2\\\\1 & 3 & 1 & 2\\\\0 & 2 & 1 & 1\\\\1 & 2 & 2 & 0\\end{matrix}\\right]\\)\n\n\n\ngensec(A)\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 1 & -1 & -1\\end{matrix}\\right]\\)\n\n\nPor lo tanto la ecuación de \\(U\\) es \\(x_2-x_3-x_4=0\\).\n\n\nEjemplo 2\nSea ahora el subespacio vectorial de \\(\\mathbb{R}^4\\) con ecuaciones \\(x_1+x_2+x_4=0\\), \\(2x_1-x_2+x_4=0\\).\n\nB=Matrix([[1,1,0,1],[2,-1,0,1]])\ngensec(B)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & 0 & - \\frac{3}{2}\\\\0 & 0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nPor lo que nuestro subespacio es \\(\\mathcal{L}(\\{(1,1/2,0,-3/2),(0,0,1,0)\\})\\).",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#suma-e-intersección-de-subespacios",
    "href": "ALME-espacios-vectoriales.html#suma-e-intersección-de-subespacios",
    "title": "Espacios vectoriales",
    "section": "Suma e intersección de subespacios",
    "text": "Suma e intersección de subespacios\n\nEjercicio\nDeterminar bases de la suma y la intersección de los subespacios \\(U=\\mathcal{L}((1,1,0,0), (0,0,1,1))\\) y \\(W=\\mathcal{L}((1,1,1,0), (1,1,1,1))\\) de \\(\\mathbb{R}^4\\).\nPara calcular la suma, basta con calcular una base del espacio vectorial generado por la unión de los generadores de \\(U\\) y \\(V\\).\n\nU=Matrix([[1,1,0,0],[0,0,1,1]])\nV=Matrix([[1,1,1,0],[1,1,1,1]])\nU.col_join(V).rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nLuego la suma está generada por \\(\\{(1,1,0,0),(0,0,1,0),(0,0,0,1)\\}\\).\nPara la intersección, calculamos las ecuaciones implícitas de \\(U\\) y \\(V\\), y luego las juntamos.\n\necU=gensec(U)\necU\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 0 & 0\\\\0 & 0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nLas ecuaciones de \\(U\\) son \\(x-y=0\\), \\(z-t=0\\).\n\necV=gensec(V)\necV\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & -1 & 0\\\\0 & 1 & -1 & 0\\end{matrix}\\right]\\)\n\n\nLas de \\(V\\) son \\(x-z=0\\), \\(y-z=0\\). Las de la intersección por tanto se obtienen juntando estas ecuaciones y reduciendo.\n\necUiV=ecU.col_join(ecV).rref(pivots=False)\necUiV[:ecUiV.rank(),:]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & -1\\\\0 & 1 & 0 & -1\\\\0 & 0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nPor tanto las ecuaciones de la intersección son \\[\n\\left\\{ \\begin{array}{rcl}\nx - t &=& 0, \\\\\ny - t &=&  0, \\\\\nz - t &=& 0.\n\\end{array} \\right.\n\\]\n\ngensec(ecUiV)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & 1\\end{matrix}\\right]\\)\n\n\nTeniendo así que \\(U\\cap V\\) está generado por \\((1,1,1,1)\\).",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#suma-directa-de-subespacios",
    "href": "ALME-espacios-vectoriales.html#suma-directa-de-subespacios",
    "title": "Espacios vectoriales",
    "section": "Suma directa de subespacios",
    "text": "Suma directa de subespacios\n\nEjercicio\nDado el subespacio \\(U\\) de \\(\\mathbb{R}^4\\) de ecuaciones cartesianas \\[\n\\left\\{ \\begin{array}{ccc}\nx+y & = & 0, \\\\\nt & = & 0.\n\\end{array} \\right.\n\\] Obtener un subespacio complementario de \\(U\\).\n\necU=Matrix([[1,1,0,0],[0,0,0,1]])\nU=gensec(ecU)\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 0 & 0\\\\0 & 0 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\nU.col_join(ecU).rank()\n\n4\n\n\nUn complementario es por tanto \\(\\mathcal{L}(\\{(1,1,0,0),(0,0,0,1)\\})\\) (los vectores cuyas coordenadas son los coeficientes de las ecuaciones de \\(U\\)).\n\n\nEjercicio\nSe consideran los subespacios de \\(\\mathcal{P}_2(\\mathbb{R})\\) \\(U=\\mathcal{L}(1+x^2)\\) y \\(W\\) con ecuación cartesiana respecto de base estándar \\(x_1 + x_3= 0\\). Comprobar que \\(\\mathcal{P}_2(\\mathbb{R})=U\\oplus W\\) y descomponer el vector \\(1+3x+3x^2\\) como suma de un vector de \\(U\\) y uno de \\(W\\).\nRespecto a la base estándar \\(B=\\{1,x,x^2\\}\\), \\(U\\) está generado por \\((1,0,1)\\). Encontremos una base para \\(W\\).\n\nU=Matrix([[1,0,1]])\necW=Matrix([[1,0,1]])\nW=gensec(ecW)\nW\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & -1\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nComo\n\nU.col_join(W).rank()\n\n3\n\n\nTenemos que \\(U+W=\\mathcal{P}_2(\\mathbb{R})\\). Además, como \\(U\\) tiene dimensión uno y \\(W\\) tiene dimensión dos, la intersección debe tener dimensión cero, pues \\(\\dim(U\\cap W) = \\dim(U) + \\dim(W) -\\dim(U+W)= 1 +2 -3 =0\\). Por tanto, \\(\\mathcal{P}_2(\\mathbb{R})=U\\oplus W\\). Esto también queda claro por el hecho de que la ecuación cartesianda de \\(W\\) tiene como coeficientes el vector que genera a \\(U\\).\nEl polinomio \\(1+3x+3x^2\\) tiene coordenadas \\((1,3,3)\\) respecto de la base estándar. Calculemos sus coordenadas respecto de la base formada por la unión de las bases de \\(U\\) y \\(W\\), \\(B'=\\{(1,0,1),(1,0,-1),(0,1,0)\\}\\).\n\ncb=U.col_join(W)\ncb\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 1\\\\1 & 0 & -1\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\nlinsolve((cb,Matrix([1,3,3])))\n\n\\(\\displaystyle \\left\\{\\left( 2, \\  3, \\  -1\\right)\\right\\}\\)\n\n\nLuego \\(1+3x+3x^2=(2,-1,3)_{B'}=2(1+x^2)-(1-x^2)+3x\\), con \\(2+2x^2\\in U\\) y \\(-1+3x+x^2\\in W\\).",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#matriz-de-gram",
    "href": "ALME-espacios-vectoriales.html#matriz-de-gram",
    "title": "Espacios vectoriales",
    "section": "Matriz de Gram",
    "text": "Matriz de Gram\n\nEjercicio\nEn el espacio vectorial \\(\\mathcal{P}_2(\\mathbb{K})\\) de los polinomios de grado menor o igual que \\(2\\), calcular la matriz de Gram del producto escalar definido por \\[ \\langle p(x),q(x)\\rangle = \\int_{0}^{1} p(x)q(x)dx \\] respecto de la base estándar \\(B=\\{1,x,x^2 \\}\\).\n\nfrom sympy import Symbol\n\n\nx=Symbol(\"x\")\nx\n\n\\(\\displaystyle x\\)\n\n\n\nB=[1,x,x**2]\n\n\nfrom sympy import integrate\n\n\nintegrate(B[0]*B[1],(x,0,1))\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\n\nG=Matrix(3,3,lambda i,j:integrate(B[i]*B[j],(x,0,1)))\nG\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3}\\\\\\frac{1}{2} & \\frac{1}{3} & \\frac{1}{4}\\\\\\frac{1}{3} & \\frac{1}{4} & \\frac{1}{5}\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nCon el producto escalar anterior y los polinomios \\(p(x)= 1+6x-10x^2\\) y \\(q(x)=1+2x+4x^2\\), calcular 1. \\(\\langle p(x), q(x) \\rangle\\), 2. \\(|| p(x)||\\), \\(||q(x) ||\\),\n3. el ángulo que determinan \\(p(x)\\) y \\(q(x)\\).\nPodemos usar la matriz de Gram antes calculada\n\np=1+6*x-10*x**2\nq=1+2*x+4*x**2\n\n\nintegrate(p*q,(x,0,1))\n\n\\(\\displaystyle 0\\)\n\n\nO bien usando las coordenadas de \\(p(x)\\) y \\(q(x)\\) en la base estándar.\n\nMatrix([[1,6,-10]])*G*Matrix([1,2,4])\n\n\\(\\displaystyle \\left[\\begin{matrix}0\\end{matrix}\\right]\\)\n\n\nEn particular esto implica que son ortogonales (el ángulo que forman es \\(\\pi/2\\)).\nEn cuanto a las normas\n\nfrom sympy import sqrt\n\n\nMatrix([[1,6,-10]])*G*Matrix([1,6,-10])\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{7}{3}\\end{matrix}\\right]\\)\n\n\n\nsqrt(_[0])\n\n\\(\\displaystyle \\frac{\\sqrt{21}}{3}\\)\n\n\n\nfrom sympy import simplify\n\n\nsimplify(sqrt(integrate(q**2,(x,0,1))))\n\n\\(\\displaystyle \\frac{\\sqrt{355}}{5}\\)",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#cálculo-de-una-base-ortogonal-usando-el-método-de-gram-schmidt",
    "href": "ALME-espacios-vectoriales.html#cálculo-de-una-base-ortogonal-usando-el-método-de-gram-schmidt",
    "title": "Espacios vectoriales",
    "section": "Cálculo de una base ortogonal usando el método de Gram-Schmidt",
    "text": "Cálculo de una base ortogonal usando el método de Gram-Schmidt\n\nEjercicio\nEn \\(\\mathbb{R}^3\\) con el producto escalar usual, calcular una base ortogonal a partir de los vectores \\(\\{u_1=(1,1,-1), u_2=(1,-1,1),u_3=(-1,1,1) \\}\\).\nGramSchmidt ortogonaliza.\n\nfrom sympy import GramSchmidt\n\nPero no admite matrices como argumentos, sino listas de vectores (matrices con una sola columna).\n\nU.tolist()\n\n[[1, 0, 1]]\n\n\n\nB=[Matrix([1,1,-1]),Matrix([1,-1,1]),Matrix([-1,1,1])]\nB\n\n[Matrix([\n [ 1],\n [ 1],\n [-1]]),\n Matrix([\n [ 1],\n [-1],\n [ 1]]),\n Matrix([\n [-1],\n [ 1],\n [ 1]])]\n\n\n\ngmB=GramSchmidt(B)\ngmB\nfor v in gmB:\n    print(v.T.tolist())\n\n[[1, 1, -1]]\n[[4/3, -2/3, 2/3]]\n[[0, 1, 1]]\n\n\nVeamos que efectivamente es una base ortogonal.\n\nMatrix(3,3,lambda i,j: gmB[i].dot(gmB[j]))\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & 0 & 0\\\\0 & \\frac{8}{3} & 0\\\\0 & 0 & 2\\end{matrix}\\right]\\)\n\n\nSi queremos ortonormalizar, debememos pasar el argumento True a GramSchmidt.\n\nfor v in GramSchmidt(B,True):\n    print(v.T.tolist())\n\n[[sqrt(3)/3, sqrt(3)/3, -sqrt(3)/3]]\n[[sqrt(6)/3, -sqrt(6)/6, sqrt(6)/6]]\n[[0, sqrt(2)/2, sqrt(2)/2]]\n\n\n\ngmB=GramSchmidt(B,True)\ngmB\n\n[Matrix([\n [ sqrt(3)/3],\n [ sqrt(3)/3],\n [-sqrt(3)/3]]),\n Matrix([\n [ sqrt(6)/3],\n [-sqrt(6)/6],\n [ sqrt(6)/6]]),\n Matrix([\n [        0],\n [sqrt(2)/2],\n [sqrt(2)/2]])]\n\n\n\nUo=Matrix(3,3,[0]*9)\nfor i in range(3):\n    Uo[:,i]=gmB[i]\nUo\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{6}}{3} & 0\\\\\\frac{\\sqrt{3}}{3} & - \\frac{\\sqrt{6}}{6} & \\frac{\\sqrt{2}}{2}\\\\- \\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{6}}{6} & \\frac{\\sqrt{2}}{2}\\end{matrix}\\right]\\)\n\n\n\nUo*Uo.T\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nEn \\(\\mathbb{R}^3\\) se considera el producto escalar que, con respecto de la base canónica, viene dado por la matriz de Gram\n\\[ G=\\begin{pmatrix}\n2 & 1 & 1 \\\\\n1 & 2 & 1 \\\\\n1 & 1 & 2\n\\end{pmatrix}.\n\\]\nCalcular una base ortogonal a partir de los vectores \\(\\{(1,-1,0),(0,1,1),(0,0,1)\\}\\).\n\nG=Matrix([(2,1,1),(1,2,1),(1,1,2)])\nU=[Matrix([1,-1,0]),Matrix([0,1,1]),Matrix([0,0,1])]\n\nDefinimos nuestra función que implementa el proceso de Gram-Schmidt.\n\ndef gmm(U,G):\n    n=U[0].rows\n    m=len(U)\n    E=Matrix(n,m,[0]*n*m)\n    E[:,0]=U[0]\n    for j in range(1,m):\n        lmbd=[0]*j\n        for i in range(j):\n            lmbd[i]=-(U[j].T*G*E[:,i])[0]/(E[:,i].T*G*E[:,i])[0]\n        E[:,j]=U[j]+E[:,:j]*Matrix(lmbd)\n    return E\n\n\ngmm(U,G)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & - \\frac{3}{11}\\\\-1 & \\frac{1}{2} & - \\frac{3}{11}\\\\0 & 1 & \\frac{5}{11}\\end{matrix}\\right]\\)",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-espacios-vectoriales.html#complemento-ortogonal-proyecciones",
    "href": "ALME-espacios-vectoriales.html#complemento-ortogonal-proyecciones",
    "title": "Espacios vectoriales",
    "section": "Complemento ortogonal, proyecciones",
    "text": "Complemento ortogonal, proyecciones\n\nEjercicio\nSe considera en \\(\\mathbb{R}^3\\) el producto escalar cuya matriz de Gram respecto de la base canónica es\n\\[\\begin{pmatrix}1& 0 & 0\\\\ 0& 1 & 1 \\\\ 0 &1 & 2\\end{pmatrix}.\\]\nPara el subespacio \\(U: x+y=0\\), determinar una base de \\(U^{\\perp}\\).\nEmpezamos calculando una base para \\(U\\) a partir de sus ecuaciones.\n\necU=Matrix([[1,1,0]])\nU=gensec(ecU)\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 0\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nLlamamos \\(P\\) a la matriz de Gram del producto escalar.\n\nP=Matrix([(1,0,0),(0,1,1),(0,1,2)])\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 1\\\\0 & 1 & 2\\end{matrix}\\right]\\)\n\n\nEl espacio ortogonal a \\(U\\) tendrá de ecuaciones \\((-1,1,0)P(x,y,z)^t=0\\), \\((0,0,1)P(x,y,z)^t=0\\).\n\nfrom sympy import symbols\n\n\nx,y,z=symbols(\"x,y,z\")\n\n\nU*P*Matrix([x,y,z])\n\n\\(\\displaystyle \\left[\\begin{matrix}x - y - z\\\\y + 2 z\\end{matrix}\\right]\\)\n\n\nLos coeficientes de esas ecuaciones son\n\necUo=U*P\necUo\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & -1\\\\0 & 1 & 2\\end{matrix}\\right]\\)\n\n\n\ngensec(ecUo)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & -1\\end{matrix}\\right]\\)\n\n\nPor lo que una base para \\(U^\\perp\\) es \\(\\{(1,2,-1)\\}\\).\n\nlinsolve((ecUo,Matrix([0,0])))\n\n\\(\\displaystyle \\left\\{\\left( - \\tau_{0}, \\  - 2 \\tau_{0}, \\  \\tau_{0}\\right)\\right\\}\\)\n\n\n\n\nEjercicio\nSe considera en \\(\\mathbb{R}^3\\) el producto escalar cuya matriz de Gram respecto de la base canónica es\n\\[\\begin{pmatrix}1& 0 & 0\\\\ 0& 1 & 1 \\\\ 0 &1 & 2\\end{pmatrix}.\\]\nDeterminar la proyección del vector \\((1,2,1)\\) sobre el subespacio \\(U: x+y=0\\).\nSabemos que una base para \\(U\\) es \\(\\{(-1,1,0),(0,0,1)\\}\\) y una para \\(U^\\perp\\) es \\(\\{(1,2,-1)\\}\\). Por tanto, su unión es una base de \\(\\mathbb{R}^3\\). Escribamos \\((1,2,1)\\) en función de esa base.\n\nB=Matrix([(-1,1,0),(0,0,1),(1,2,-1)]).T\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 1\\\\1 & 0 & 2\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\n\nv=Matrix([1,2,1])\n\n\nlinsolve((B,v))\n\n\\(\\displaystyle \\left\\{\\left( 0, \\  2, \\  1\\right)\\right\\}\\)\n\n\nPor lo que \\((1,2,1)=2(0,0,1)+(1,2,-1)\\), y de esta forma la proyección de \\((1,2,1)\\) en \\(U\\) es \\((0,0,2)\\).\nUna forma alternativa es usar los coeficientes de Fourier respecto a una base ortogonal. Como la \\((1,2,1)\\) es la suma de las proyecciones de ese vector en \\(U\\) y \\(U^\\perp\\), basta calcular la proyección en \\(U^\\perp\\) y luego restarle a \\((1,2,1)\\) lo que obtengamos.\nEl coeficiente de Fourier respecto a \\((1,2,-1)\\) es\n\n(v.T*P*Matrix([1,2,-1]))[0]/(Matrix([1,2,-1]).T*P*Matrix([1,2,-1]))[0]\n\n\\(\\displaystyle 1\\)\n\n\nAsí la proyección en \\(U\\) se calcula como\n\nv-Matrix([1,2,-1])\n\n\\(\\displaystyle \\left[\\begin{matrix}0\\\\0\\\\2\\end{matrix}\\right]\\)",
    "crumbs": [
      "Espacios vectoriales"
    ]
  },
  {
    "objectID": "ALME-diagonalizacion.html",
    "href": "ALME-diagonalizacion.html",
    "title": "Diagonalización",
    "section": "",
    "text": "En este documento ilustraremos cómo usar Python para resolver los problemas tipo propuestos por L. Merino y E. Santos en página de resolución de ejercicios tipo correspondientes al bloque “Diagonalización”.",
    "crumbs": [
      "Diagonalización"
    ]
  },
  {
    "objectID": "ALME-diagonalizacion.html#ejemplo",
    "href": "ALME-diagonalizacion.html#ejemplo",
    "title": "Diagonalización",
    "section": "Ejemplo",
    "text": "Ejemplo\nDada la matriz\n\\[\nA=\\left(\n\\begin{array}{ccc}\n5 & 1 & -3 \\\\\n1 & 5 & -3 \\\\\n2 & 2 & -2\n\\end{array}\\right).\n\\]\nDeterminar si es o no diagonalizable y, en caso de que lo sea, determinar su forma diagonal y una matriz de paso.\n\nfrom sympy import Matrix, eye\n\n\nA=Matrix([(5,1,-3),(1,5,-3),(2,2,-2)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}5 & 1 & -3\\\\1 & 5 & -3\\\\2 & 2 & -2\\end{matrix}\\right]\\)\n\n\nPodemos calcular los valores propios con eigenvals.\n\nA.eigenvals()\n\n{4: 2, 0: 1}\n\n\nO ver toda la información (incluyendo multiplicidades y vectores propios) con eigenvects.\n\nA.eigenvects()\n\n[(0,\n  1,\n  [Matrix([\n   [1/2],\n   [1/2],\n   [  1]])]),\n (4,\n  2,\n  [Matrix([\n   [-1],\n   [ 1],\n   [ 0]]),\n   Matrix([\n   [3],\n   [0],\n   [1]])])]\n\n\nDe la salida que obtenemos, observamos que tenemos dos valores propios: 0 con multiplicidad algebraica y geométrica 1, y 4 con multiplicidad algebraica y geométrica 2. También podemos construir la matriz de paso con los datos que hemos obtenido, pero es más fácil usar diagonalize.\n\nA.diagonalize()\n\n(Matrix([\n [1, -1, 3],\n [1,  1, 0],\n [2,  0, 1]]),\n Matrix([\n [0, 0, 0],\n [0, 4, 0],\n [0, 0, 4]]))\n\n\n\nP, D = A.diagonalize()\n\n\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 3\\\\1 & 1 & 0\\\\2 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nD\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0\\\\0 & 4 & 0\\\\0 & 0 & 4\\end{matrix}\\right]\\)\n\n\nComprobemos que efectivamente \\(P^{-1}AP\\) es diagonal.\n\nP.inv()*A*P==D\n\nTrue\n\n\nHagamos este proceso paso a paso usando calculando el polinomio característico y los subespacios propios.\nEmpezamos calculando el polinomio característico de A y sus raíces (valores propios).\n\nfrom sympy.abc import x\n\n\nA.charpoly()\n\n\\(\\displaystyle \\operatorname{PurePoly}{\\left( \\lambda^{3} - 8 \\lambda^{2} + 16 \\lambda, \\lambda, domain=\\mathbb{Z} \\right)}\\)\n\n\n\nA.charpoly(28)\n\n\\(\\displaystyle \\operatorname{PurePoly}{\\left( 28^{3} - 8 28^{2} + 16 28, 28, domain=\\mathbb{Z} \\right)}\\)\n\n\n\np=A.charpoly(x)\np\n\n\\(\\displaystyle \\operatorname{PurePoly}{\\left( x^{4} - 8 x^{3} + 13 x^{2} - 6 x, x, domain=\\mathbb{Z} \\right)}\\)\n\n\n\np.all_roots()\n\n[0, 1, 1, 6]\n\n\nPor lo que 0 tiene multiplicidad 1, y 4 multiplicidad 2.\nCalculemos ahora los subespacios propios asociados a cada uno de esos valores propios.\n\nV0=A.nullspace()\nV0\n\n[Matrix([\n [-1],\n [ 0],\n [ 2],\n [ 1]])]\n\n\n\nV4=(A-4*eye(3)).nullspace()\nV4\n\nShapeError: Matrix size mismatch: (4, 4) + (3, 3)\n\n\nPodemos usar hstack para combinar los vectores que hemos encontrado.\n\nP=Matrix.hstack(V0[0],V4[0],V4[1])\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{2} & -1 & 3\\\\\\frac{1}{2} & 1 & 0\\\\1 & 0 & 1\\end{matrix}\\right]\\)\n\n\nO de una forma más compacta.\n\nMatrix.hstack(*(V0+V4))\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{2} & -1 & 3\\\\\\frac{1}{2} & 1 & 0\\\\1 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0\\\\0 & 4 & 0\\\\0 & 0 & 4\\end{matrix}\\right]\\)\n\n\n\nEjercicio\nEstudiar si la siguiente matriz es o no diagonalizable y, en tal caso, determinar su forma diagonal y una matriz de paso. \\[\nA=\\left(\n\\begin{array}{ccc}\n2 & 1 & -2 \\\\\n0 & 2 & -1 \\\\\n0 & 0 & 1\n\\end{array}\\right)\n\\]\n\nA=Matrix([(2,1,-2),(0,2,-1),(0,0,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 1 & -2\\\\0 & 2 & -1\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nAl ser triangular, ya sabemos cuáles van a ser los valores propios (2 y 1).\n\np=A.charpoly(x)\np.all_roots()\n\n[1, 2, 2]\n\n\nEl valor propio 2 tiene multiplicidad algebraica 2, pero sin embargo, su subespacio propio asociado tiene dimensión uno, por lo que \\(A\\) no es diagonalizable.\n\nV2=(A-2*eye(3)).nullspace()\nV2\n\n[Matrix([\n [1],\n [0],\n [0]])]\n\n\n\ntry:\n    A.diagonalize()\nexcept:\n    print(\"No es diagonalizable\")\n\nNo es diagonalizable\n\n\n\n\nEjercicio\nRazonar que la siguiente matriz \\(A\\) es diagonalizable y determinar su forma diagonal y una matriz de paso. Determinar \\(A^k\\) en función de \\(k\\). \\[\nA=\\left(\n\\begin{array}{cccc}\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & -2 \\\\\n1 & 0 & -2 & 5\n\\end{array}\\right)\n\\]\n\nA=Matrix([(1,0,0,1),(0,1,0,0),(0,0,1,-2),(1,0,-2,5)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 1\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & -2\\\\1 & 0 & -2 & 5\\end{matrix}\\right]\\)\n\n\n\nA.eigenvects()\n\n[(0,\n  1,\n  [Matrix([\n   [-1],\n   [ 0],\n   [ 2],\n   [ 1]])]),\n (1,\n  2,\n  [Matrix([\n   [0],\n   [1],\n   [0],\n   [0]]),\n   Matrix([\n   [2],\n   [0],\n   [1],\n   [0]])]),\n (6,\n  1,\n  [Matrix([\n   [ 1/5],\n   [   0],\n   [-2/5],\n   [   1]])])]\n\n\nVemos que las multiplicidades algebraicas y geométricas coinciden. Por tanto, A es diagonalizable.\n\nP,D = A.diagonalize()\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 2 & 1\\\\0 & 1 & 0 & 0\\\\2 & 0 & 1 & -2\\\\1 & 0 & 0 & 5\\end{matrix}\\right]\\)\n\n\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 6\\end{matrix}\\right]\\)\n\n\nCalculemos P de nuevo “a mano”.\n\nA.charpoly().all_roots()\n\n[0, 1, 1, 6]\n\n\n\nV0=A.nullspace()\nV0\n\n[Matrix([\n [-1],\n [ 0],\n [ 2],\n [ 1]])]\n\n\n\nV1=(A-eye(4)).nullspace()\nV1\n\n[Matrix([\n [0],\n [1],\n [0],\n [0]]),\n Matrix([\n [2],\n [0],\n [1],\n [0]])]\n\n\n\nV6=(A-6*eye(4)).nullspace()\nV6\n\n[Matrix([\n [ 1/5],\n [   0],\n [-2/5],\n [   1]])]\n\n\n\nP=Matrix.hstack(*(V0+V1+V6))\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 2 & \\frac{1}{5}\\\\0 & 1 & 0 & 0\\\\2 & 0 & 1 & - \\frac{2}{5}\\\\1 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 6\\end{matrix}\\right]\\)\n\n\nCalculemos ahora las potencias de \\(A\\). Para todo \\(k\\) entero positivo, \\(A^k=(P^{-1}DP)^k=P^{-1}D^kP\\).\n\nfrom sympy import var, powsimp\n\n\nk=var(\"k\", integer=True, nonzero=True)\n\n\nD=Matrix.diag([0,1,1,6])\nD\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 6\\end{matrix}\\right]\\)\n\n\n\nD**k\n\n\\(\\displaystyle \\left[\\begin{matrix}0^{k} & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 6^{k}\\end{matrix}\\right]\\)\n\n\n\nAk=P.inv()*Matrix.diag([0,1,1,6**k])*P\nAk\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{6^{k}}{6} + \\frac{2}{3} & 0 & \\frac{1}{3} & \\frac{6^{k}}{6} - \\frac{2}{15}\\\\0 & 1 & 0 & 0\\\\\\frac{2}{5} & 0 & \\frac{1}{5} & - \\frac{2}{25}\\\\\\frac{5 \\cdot 6^{k}}{6} - \\frac{2}{3} & 0 & - \\frac{1}{3} & \\frac{5 \\cdot 6^{k}}{6} + \\frac{2}{15}\\end{matrix}\\right]\\)\n\n\n\npowsimp(Ak)\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{6^{k}}{6} + \\frac{2}{3} & 0 & \\frac{1}{3} & \\frac{6^{k}}{6} - \\frac{2}{15}\\\\0 & 1 & 0 & 0\\\\\\frac{2}{5} & 0 & \\frac{1}{5} & - \\frac{2}{25}\\\\\\frac{5 \\cdot 6^{k}}{6} - \\frac{2}{3} & 0 & - \\frac{1}{3} & \\frac{5 \\cdot 6^{k}}{6} + \\frac{2}{15}\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nEstudiar para qué valores de los parámetros \\(a\\) y \\(b\\) es diagonalizable la matriz \\[\nA=\\left(\n\\begin{array}{ccc}\n1 & a & 0 \\\\\n0 & 0 & b \\\\\n0 & b & 0\n\\end{array}\\right).\n\\]\n\nfrom sympy.abc import a,b\n\n\nA=Matrix([[1,a,0],[0,0,b],[0,b,0]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & 0\\\\0 & 0 & b\\\\0 & b & 0\\end{matrix}\\right]\\)\n\n\n\np=A.charpoly(x)\np\n\n\\(\\displaystyle \\operatorname{PurePoly}{\\left( x^{3} - x^{2} -  b^{2} x + b^{2}, x, domain=\\mathbb{Z}\\left[b\\right] \\right)}\\)\n\n\nFactorizamos el polinomio característico.\n\np.factor_list()\n\n(1,\n [(PurePoly(x - 1, x, domain='ZZ[b]'), 1),\n  (PurePoly(x - b, x, domain='ZZ[b]'), 1),\n  (PurePoly(x + b, x, domain='ZZ[b]'), 1)])\n\n\nO bien como expresión.\n\np.as_expr().factor()\n\n\\(\\displaystyle \\left(- b + x\\right) \\left(b + x\\right) \\left(x - 1\\right)\\)\n\n\nO bien con solve.\n\nfrom sympy import solve\n\n\nsolve(p.as_expr(),x)\n\n[1, -b, b]\n\n\nLos valores propios son \\(\\{1,b,-b\\}\\). Así si \\(b\\not\\in\\{0,1,-1\\}\\), los tres valores propios son diferentes y la matriz es diagonalizable.\nEstudiemos ahora qué ocurre para \\(b=0\\), en cuyo caso los valores propios son \\(1\\) y \\(0\\) con multiplicidad dos. Nos interesa por tanto ver si el subespacio propio asociado a \\(0\\) tiene dimensión dos.\n\nAb0=A.subs({b:0})\nAb0\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & 0\\\\0 & 0 & 0\\\\0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nQue tiene rango 1, por lo que que el valor propio 0 tiene multiplicidad geométrica 2.\n\nAb0.nullspace()\n\n[Matrix([\n [-a],\n [ 1],\n [ 0]]),\n Matrix([\n [0],\n [0],\n [1]])]\n\n\nPor lo que para \\(b=0\\), la multiplicidad algebraica y geométrica de cada valor propio coincide, siendo así Ab0 diagonalizable.\n\nP0, D= Ab0.diagonalize()\nP0\n\n\\(\\displaystyle \\left[\\begin{matrix}- a & 0 & 1\\\\1 & 0 & 0\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\nP0.inv()*Ab0*P0\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0\\\\0 & 0 & 0\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nVeamos ahora el caso \\(b=1\\). Los valores propios son \\(1\\), con multiplicidad dos, y \\(-1\\).\n\nAb1=A.subs({b:1})\nAb1\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & 0\\\\0 & 0 & 1\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\nAb1-eye(3)\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & a & 0\\\\0 & -1 & 1\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nEn este caso el rango de \\(A-I\\) depende de \\(a\\). - Si \\(a\\neq 0\\), el rango es dos, y la dimension del subespacio propio asociado a 1 sería 1, por lo que la matriz no sería diagonalizable. - Si \\(a=0\\), entonces la matriz es diagonalizable, pues el rango de \\(A-I\\) es 1, y por tanto su núcleo tiene dimensión 2.\nHay que tener cuidado con usar rank o rref directamente, pues sympy considera a como un símbolo.\n\n(Ab1-eye(3)).rank()\n\n2\n\n\n\n(Ab1-eye(3)).rref()\n\n(Matrix([\n [0, 1, 0],\n [0, 0, 1],\n [0, 0, 0]]),\n (1, 2))\n\n\nPodemos considerar el menor \\(2\\times 2\\) superior derecho, que nos proporciona la distinción de los valores de \\(a\\) que hemos hecho arriba.\n\nM=(Ab1-eye(3))[:2,1:]\nM\n\n\\(\\displaystyle \\left[\\begin{matrix}a & 0\\\\-1 & 1\\end{matrix}\\right]\\)\n\n\n\nM.det()\n\n\\(\\displaystyle a\\)\n\n\nPara \\(b=-1\\), tenemos como valores propios a 1 (multiplicidad 2) y -1.\n\nAbm1=A.subs({b:1})\nAbm1\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & 0\\\\0 & 0 & 1\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\n(Abm1-eye(3))\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & a & 0\\\\0 & -1 & 1\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nRepitiéndose la distinción que hicimos para \\(b=1\\).",
    "crumbs": [
      "Diagonalización"
    ]
  },
  {
    "objectID": "Descomposicion-valores-singulares.html",
    "href": "Descomposicion-valores-singulares.html",
    "title": "Descomposición en valores singulares",
    "section": "",
    "text": "Para ilustrar la descomposición en valores singulares de una matriz vamos a hacer uso del Ejemplo VI.1.8 de [I. Ojeda, J. Gago, Métodos matemáticos para la Estadística].\nOtro buen ejemplo de cálculo de esta descomposición paso a paso se puede encontrar aquí.\nVamos a utilizar singular_value_decomposition que apareció en la versión 1.8 de sympy. Si nuestra versión es anterior, podemos ejecutar pip install \"sympy&gt;=1.8\" (luego tenemos que reiniciar el núcleo).\n\nfrom sympy import Matrix\n\n\nA=Matrix([(2,0,1),(3,-1,1),(-2,4,1),(1,1,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 1\\\\3 & -1 & 1\\\\-2 & 4 & 1\\\\1 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nU,D,V=A.singular_value_decomposition()\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{2} & - \\frac{\\sqrt{14}}{14}\\\\\\frac{1}{2} & - \\frac{\\sqrt{14}}{7}\\\\\\frac{1}{2} & \\frac{3 \\sqrt{14}}{14}\\\\\\frac{1}{2} & 0\\end{matrix}\\right]\\)\n\n\n\nD\n\n\\(\\displaystyle \\left[\\begin{matrix}2 \\sqrt{3} & 0\\\\0 & 2 \\sqrt{7}\\end{matrix}\\right]\\)\n\n\n\nV\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{\\sqrt{3}}{3} & - \\frac{\\sqrt{2}}{2}\\\\\\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{2}}{2}\\\\\\frac{\\sqrt{3}}{3} & 0\\end{matrix}\\right]\\)\n\n\n\nU*D*V.T==A\n\nTrue\n\n\n\nProceso paso a paso a partir de los valores propios de \\(A^tA\\)\nVamos a hacer el proceso paso a paso. Como sabemos, los valores singulares son las raíces cuadradas de los valores propios de \\(A^tA\\).\n\nfrom sympy import sqrt, eye, GramSchmidt\n\n\nA.T*A\n\n\\(\\displaystyle \\left[\\begin{matrix}18 & -10 & 4\\\\-10 & 18 & 4\\\\4 & 4 & 4\\end{matrix}\\right]\\)\n\n\n\nev=(A.T*A).eigenvals()\nev\n\n{28: 1, 12: 1, 0: 1}\n\n\nTomamos las raíces cuadradas de los valores no nulos (queremos una descomposición corta).\n\nd=[sqrt(a) for a in ev.keys() if a!=0]\nd\n\n[2*sqrt(7), 2*sqrt(3)]\n\n\nLa matriz \\(V\\) está formada por los vectores propios correspondientes a 28 y 12.\n\nV28=(A.T*A - 28*eye(3)).nullspace()\nV28\n\n[Matrix([\n [-1],\n [ 1],\n [ 0]])]\n\n\n\nV12=(A.T*A - 12*eye(3)).nullspace()\nV12\n\n[Matrix([\n [1],\n [1],\n [1]])]\n\n\nJuntamos las bases, ortogonalizamos por Gram-Schmidt y las ponemos como columnas en una matriz.\n\nV=Matrix.hstack(*GramSchmidt(V28+V12,True))\nV\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{3}}{3}\\\\\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{3}}{3}\\\\0 & \\frac{\\sqrt{3}}{3}\\end{matrix}\\right]\\)\n\n\n\nD=Matrix.diag(d)\nD\n\n\\(\\displaystyle \\left[\\begin{matrix}2 \\sqrt{7} & 0\\\\0 & 2 \\sqrt{3}\\end{matrix}\\right]\\)\n\n\nComo \\(A=UDV^t\\), tenemos \\(AV=UD\\), luego \\(U\\) se calcula como sigue.\n\nU=A*V*D.inv()\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{\\sqrt{14}}{14} & \\frac{1}{2}\\\\- \\frac{\\sqrt{14}}{7} & \\frac{1}{2}\\\\\\frac{3 \\sqrt{14}}{14} & \\frac{1}{2}\\\\0 & \\frac{1}{2}\\end{matrix}\\right]\\)\n\n\nComprobemos que es efectivamente una descomposición de \\(A\\).\n\nU*D*V.T==A\n\nTrue",
    "crumbs": [
      "Descomposición por valores singulares"
    ]
  },
  {
    "objectID": "Inversas-generalizadas.html",
    "href": "Inversas-generalizadas.html",
    "title": "Inversa generalizada de Moore-Penrose",
    "section": "",
    "text": "Existen varias formas de calcular la inversa generalizada de Moore-Penrose de una matriz. Aquí expondremos algunas de ellas usando diversas librerías de sympy.",
    "crumbs": [
      "Inversas generalizadas"
    ]
  },
  {
    "objectID": "Inversas-generalizadas.html#cálculo-a-partir-de-una-descomposición-en-valores-singulares",
    "href": "Inversas-generalizadas.html#cálculo-a-partir-de-una-descomposición-en-valores-singulares",
    "title": "Inversa generalizada de Moore-Penrose",
    "section": "Cálculo a partir de una descomposición en valores singulares",
    "text": "Cálculo a partir de una descomposición en valores singulares\nSi \\(A\\) es una matriz con entradas reales y \\(UDV^t\\) es una descomposición en valores singulares corta de \\(A\\), entonces por la demostración del Teorema VI.2.2 de [I. Ojeda, J. Gago, Métodos matemáticos para la Estadística] la inversa generalizada de Moore-Penrose de \\(A\\) es \\(A^\\dagger=VD^{-1}U^t\\).\nIlustremos este cálculo usando los Ejemplos VI.1.8 y VI.2.3 de [I. Ojeda, J. Gago, Métodos matemáticos para la Estadística].\nVamos a utilizar singular_value_decomposition que apareció en la versión 1.8 de sympy. Si nuestra versión es anterior, podemos ejecutar pip install \"sympy&gt;=1.8\" (luego tenemos que reiniciar el núcleo).\n\nfrom sympy import Matrix,eye\n\n\nA=Matrix([(2,0,1),(3,-1,1),(-2,4,1),(1,1,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 1\\\\3 & -1 & 1\\\\-2 & 4 & 1\\\\1 & 1 & 1\\end{matrix}\\right]\\)\n\n\nPara calcular la inversa generalizada de Moore-Penrose usamos pinv.\n\nA.pinv()\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{5}{42} & \\frac{13}{84} & - \\frac{1}{42} & \\frac{1}{12}\\\\\\frac{1}{21} & \\frac{1}{84} & \\frac{4}{21} & \\frac{1}{12}\\\\\\frac{1}{12} & \\frac{1}{12} & \\frac{1}{12} & \\frac{1}{12}\\end{matrix}\\right]\\)\n\n\n\nUsando svd\nComo hemos visto, para calcular la descomposición en valores singulares, podemos utilizar svd.\n\nU,D,V=A.singular_value_decomposition()\nU\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{2} & - \\frac{\\sqrt{14}}{14}\\\\\\frac{1}{2} & - \\frac{\\sqrt{14}}{7}\\\\\\frac{1}{2} & \\frac{3 \\sqrt{14}}{14}\\\\\\frac{1}{2} & 0\\end{matrix}\\right]\\)\n\n\n\nD\n\n\\(\\displaystyle \\left[\\begin{matrix}2 \\sqrt{3} & 0\\\\0 & 2 \\sqrt{7}\\end{matrix}\\right]\\)\n\n\n\nV\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{\\sqrt{3}}{3} & - \\frac{\\sqrt{2}}{2}\\\\\\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{2}}{2}\\\\\\frac{\\sqrt{3}}{3} & 0\\end{matrix}\\right]\\)\n\n\n\nigA=V*D.inv()*U.T\nigA\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{5}{42} & \\frac{13}{84} & - \\frac{1}{42} & \\frac{1}{12}\\\\\\frac{1}{21} & \\frac{1}{84} & \\frac{4}{21} & \\frac{1}{12}\\\\\\frac{1}{12} & \\frac{1}{12} & \\frac{1}{12} & \\frac{1}{12}\\end{matrix}\\right]\\)\n\n\nVeamos que verifica las condiciones de inversa generalizada.\n\\(AA^\\dagger A=A\\):\n\nA*igA*A==A\n\nTrue\n\n\n\\(A^\\dagger A A^\\dagger=A^\\dagger\\):\n\nigA*A*igA==igA\n\nTrue\n\n\n\\(A A^\\dagger\\) y \\(A^\\dagger A\\) son simétricas:\n\n(A*igA).is_symmetric()\n\nTrue\n\n\n\n(igA*A).is_symmetric()\n\nTrue",
    "crumbs": [
      "Inversas generalizadas"
    ]
  },
  {
    "objectID": "Inversas-generalizadas.html#cálculo-a-partir-de-una-factorización-de-rango-pleno",
    "href": "Inversas-generalizadas.html#cálculo-a-partir-de-una-factorización-de-rango-pleno",
    "title": "Inversa generalizada de Moore-Penrose",
    "section": "Cálculo a partir de una factorización de rango pleno",
    "text": "Cálculo a partir de una factorización de rango pleno\nPodemos calcular la inversa generalizada una vez que conozcamos una factorización de rango pleno de la matriz. Ilustramos este proceso siguiendo los pasos que se explican en [L. Merino, E. Santos, Álgebra Lineal con Métodos Elementales].\n\nE,F=A.rank_decomposition()\nE\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0\\\\3 & -1\\\\-2 & 4\\\\1 & 1\\end{matrix}\\right]\\)\n\n\n\nF\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & \\frac{1}{2}\\\\0 & 1 & \\frac{1}{2}\\end{matrix}\\right]\\)\n\n\n\nE*F==A\n\nTrue\n\n\nEl rango de E y de F coincide con el rango de A.\nEl siguiente paso es calcular una inversa por la derecha de F y una inversa por la izquierda de E. Al ser ambas de rango pleno for fillas y por columnas, respectivamente, esto se puede hacer de la siguiente forma.\n\nFR=F.T*(F*F.T).inv()\nFR\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{5}{6} & - \\frac{1}{6}\\\\- \\frac{1}{6} & \\frac{5}{6}\\\\\\frac{1}{3} & \\frac{1}{3}\\end{matrix}\\right]\\)\n\n\n\nF*FR\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0\\\\0 & 1\\end{matrix}\\right]\\)\n\n\n\nEL=(E.T*E).inv()*E.T\nEL\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{9}{56} & \\frac{11}{56} & \\frac{1}{56} & \\frac{1}{8}\\\\\\frac{5}{56} & \\frac{3}{56} & \\frac{13}{56} & \\frac{1}{8}\\end{matrix}\\right]\\)\n\n\n\nEL*E\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0\\\\0 & 1\\end{matrix}\\right]\\)\n\n\n\nigrpA=FR*EL\nigrpA==A.pinv()\n\nTrue\n\n\nLa descomposición de rango pleno también se puede hacer usando la forma normal reducida por filas.\n\nfrA=Matrix.hstack(A,eye(4)).rref(pivots=False)\nfrA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & \\frac{1}{2} & 0 & 0 & - \\frac{1}{6} & \\frac{2}{3}\\\\0 & 1 & \\frac{1}{2} & 0 & 0 & \\frac{1}{6} & \\frac{1}{3}\\\\0 & 0 & 0 & 1 & 0 & \\frac{1}{3} & - \\frac{4}{3}\\\\0 & 0 & 0 & 0 & 1 & \\frac{2}{3} & - \\frac{5}{3}\\end{matrix}\\right]\\)\n\n\n\nQ=frA[:,3:]\nH=frA[:,:3]\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & - \\frac{1}{6} & \\frac{2}{3}\\\\0 & 0 & \\frac{1}{6} & \\frac{1}{3}\\\\1 & 0 & \\frac{1}{3} & - \\frac{4}{3}\\\\0 & 1 & \\frac{2}{3} & - \\frac{5}{3}\\end{matrix}\\right]\\)\n\n\n\nH\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & \\frac{1}{2}\\\\0 & 1 & \\frac{1}{2}\\\\0 & 0 & 0\\\\0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nComo \\(QA=H\\), haciendo \\(Q^{-1}H\\) recuperamos \\(A\\). Como las dos últimas filas de \\(H\\) son cero, sólo nos interesan las dos primeras filas \\(H\\) y las dos primeras columnas de \\(Q^{-1}\\).\n\nQ.inv()*H\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 1\\\\3 & -1 & 1\\\\-2 & 4 & 1\\\\1 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nE==Q.inv()[:,:2]\n\nTrue\n\n\n\nF==H[:2,:]\n\nTrue",
    "crumbs": [
      "Inversas generalizadas"
    ]
  },
  {
    "objectID": "Inversas-generalizadas.html#soluciónes-mínimo-cuadráticas",
    "href": "Inversas-generalizadas.html#soluciónes-mínimo-cuadráticas",
    "title": "Inversa generalizada de Moore-Penrose",
    "section": "Soluciónes mínimo cuadráticas",
    "text": "Soluciónes mínimo cuadráticas\nUna de las aplicaciones de la inversa generalizada de Moore-Penrose es el cálculo de soluciones óptimas (o de norma mínima) minimo-cuadráticas de un sistema de ecuaciones. Si \\(Ax=b\\) es un sistema de ecuaciones, entonces la solución óptima mínimo-cuadrática de ese sistema es \\(A^\\dagger b\\).\nIlustremos esta construcción con el Ejemplo 13 (Capítulo VII) de [L. Merino, E. Santos, Álgebra Lineal con Métodos Elementales].\n\nEjemplo\nCalcular una solución óptima mínimo-cuadrática del sistema \\(Ax=b\\) con \\[\nA=\\begin{pmatrix}\n2 & 0 & 2 & 0 \\\\\n1 & 1 & 2 & 1 \\\\\n-1 & 3 & 2 & 3\n\\end{pmatrix}\n\\] y \\(b=(6,0,2)^t\\).\n\nA=Matrix([(2,0,2,0),(1,1,2,1),(-1,3,2,3)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 2 & 0\\\\1 & 1 & 2 & 1\\\\-1 & 3 & 2 & 3\\end{matrix}\\right]\\)\n\n\n\nb=Matrix([6,0,2])\n\n\nigA=A.pinv()\nigA\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{5} & \\frac{1}{10} & - \\frac{1}{10}\\\\- \\frac{3}{70} & \\frac{1}{70} & \\frac{9}{70}\\\\\\frac{11}{70} & \\frac{4}{35} & \\frac{1}{35}\\\\- \\frac{3}{70} & \\frac{1}{70} & \\frac{9}{70}\\end{matrix}\\right]\\)\n\n\n\nxo=igA*b\nxo\n\n\\(\\displaystyle \\left[\\begin{matrix}1\\\\0\\\\1\\\\0\\end{matrix}\\right]\\)\n\n\nEl sistema no es compatible, ya que \\(Ax\\neq b\\).\n\nA*xo\n\n\\(\\displaystyle \\left[\\begin{matrix}4\\\\3\\\\1\\end{matrix}\\right]\\)\n\n\nEl siguiente ejemplo se corresponde con los Ejemplos 14 y 15 (Capítulo VII) de [L. Merino, E. Santos, Álgebra Lineal con Métodos Elementales].\n\n\nEjemplo\nLa siguiente tabla muestra la estatura media de los niños de cero a cuatro semestres de vida\n\n\n\nx\n0\n1\n2\n3\n4\n\n\n\n\ny\n50\n66.5\n75\n81\n86.5\n\n\n\nIntentemos ajustar una recta \\(y=ax+b\\). Idealmente, por los datos que tenemos \\[\n\\begin{array}{rcl}\nb & =& 50,\\\\\na + b & =& 66.5,\\\\\n2a+b &=& 75,\\\\\n3a+b &=& 81,\\\\\n4a+b &=& 86.5.\n\\end{array}\n\\] Que podemos escribir en forma de matriz como \\[\n\\begin{pmatrix}\n0 & 1\\\\\n1 & 1\\\\\n2 & 1\\\\\n3 & 1\\\\\n4 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\na \\\\ b\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n50 \\\\ 66.5 \\\\ 75 \\\\ 81 \\\\ 86.5\n\\end{pmatrix}.\n\\]\n\nA=Matrix([range(5),[1]*5]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 1\\\\1 & 1\\\\2 & 1\\\\3 & 1\\\\4 & 1\\end{matrix}\\right]\\)\n\n\n\nalt=Matrix((50,66.5,75,81,86.5))\nalt\n\n\\(\\displaystyle \\left[\\begin{matrix}50\\\\66.5\\\\75\\\\81\\\\86.5\\end{matrix}\\right]\\)\n\n\n\nigA=A.pinv()\nigA\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{1}{5} & - \\frac{1}{10} & 0 & \\frac{1}{10} & \\frac{1}{5}\\\\\\frac{3}{5} & \\frac{2}{5} & \\frac{1}{5} & 0 & - \\frac{1}{5}\\end{matrix}\\right]\\)\n\n\n\nxo=igA*alt\nxo\n\n\\(\\displaystyle \\left[\\begin{matrix}8.75\\\\54.3\\end{matrix}\\right]\\)\n\n\n\na,b = tuple(xo)\n\nAsí nuestra recta de aproximación es \\(y=8.75x+54.3\\).\n\nfrom matplotlib import pyplot\n\n\npyplot.figure(figsize = (5,5))\nx=range(5)\ny=alt.T.tolist()[0]\nr=[a*t+b for t in x]\npyplot.plot(x, y, 'b.')\npyplot.plot(x, r, 'r')\npyplot.xlabel('x')\npyplot.ylabel('y')\npyplot.show()\n\n\n\n\n\n\n\n\n\n\nEjemplo\nSupongamos que en nuestro problema de edades y alturas queremos ajustar \\(y\\) por un polinomio de grado dos en \\(x\\), \\(y=ax^2+bx+c\\). Evaluando ese polinomio en los valores que conocemos en \\(x\\) y en \\(y\\), obtenemos \\[\n\\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 1 & 1\\\\\n4 & 2 & 1\\\\\n9 & 3 & 1\\\\\n16 & 4 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\na \\\\ b \\\\ c\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n50 \\\\ 66.5 \\\\ 75 \\\\ 81 \\\\ 86.5\n\\end{pmatrix}.\n\\]\n\nA=Matrix([[i**2 for i in range(5)],range(5),[1]*5]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 1\\\\1 & 1 & 1\\\\4 & 2 & 1\\\\9 & 3 & 1\\\\16 & 4 & 1\\end{matrix}\\right]\\)\n\n\n\nigA=A.pinv()\nigA\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{7} & - \\frac{1}{14} & - \\frac{1}{7} & - \\frac{1}{14} & \\frac{1}{7}\\\\- \\frac{27}{35} & \\frac{13}{70} & \\frac{4}{7} & \\frac{27}{70} & - \\frac{13}{35}\\\\\\frac{31}{35} & \\frac{9}{35} & - \\frac{3}{35} & - \\frac{1}{7} & \\frac{3}{35}\\end{matrix}\\right]\\)\n\n\n\nxo=igA*alt\nxo\n\n\\(\\displaystyle \\left[\\begin{matrix}-1.75\\\\15.75\\\\50.8\\end{matrix}\\right]\\)\n\n\n\na,b,c=tuple(xo)\n\n\npyplot.figure(figsize = (5,5))\nx=range(5)\ny=alt.T.tolist()[0]\nxp=[i/100 for i in range(400)]\np=[a*t**2+b*t+c for t in xp]\npyplot.plot(x, y, 'b.')\npyplot.plot(xp, p, 'p',c=\"r\",linewidth=0.1)\npyplot.xlabel('x')\npyplot.ylabel('y')\npyplot.show()\n\n\n\n\n\n\n\n\nEn nuestros dos últimos ejemplos, \\(A\\) es de rango pleno por columnas, por lo que la solución minimo-cuadrática podríamos haberla calculado con \\(A^L=(A^tA)^{-1}A^t\\) (inversa a la izquierda de \\(A\\)).\n\nAL=(A.T*A).inv()*A.T\nAL\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{7} & - \\frac{1}{14} & - \\frac{1}{7} & - \\frac{1}{14} & \\frac{1}{7}\\\\- \\frac{27}{35} & \\frac{13}{70} & \\frac{4}{7} & \\frac{27}{70} & - \\frac{13}{35}\\\\\\frac{31}{35} & \\frac{9}{35} & - \\frac{3}{35} & - \\frac{1}{7} & \\frac{3}{35}\\end{matrix}\\right]\\)\n\n\n\nAL==igA\n\nTrue",
    "crumbs": [
      "Inversas generalizadas"
    ]
  },
  {
    "objectID": "Forma-Jordan.html",
    "href": "Forma-Jordan.html",
    "title": "Forma de Jordan",
    "section": "",
    "text": "En este documento implementamos algunos ejemplos de cálculo de formas canónicas de Jordan (y las matrices de paso).\nfrom sympy import Matrix, eye\nEl primer ejemplo que vamos a desarrolar usando sympy es el Ejercicio resuelto número 69 de [L. Merino, E. Santos Álgebra Lineal con Métodos Elementales].",
    "crumbs": [
      "Forma de Jordan"
    ]
  },
  {
    "objectID": "Forma-Jordan.html#ejemplo-1",
    "href": "Forma-Jordan.html#ejemplo-1",
    "title": "Forma de Jordan",
    "section": "Ejemplo 1",
    "text": "Ejemplo 1\nCalcula la forma normal de Jordan de la matriz \\[\n\\begin{pmatrix}\n0& -4 & 0 & -1 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 4 & 8 & -12 & 4\n\\end{pmatrix}.\n\\]\n\nA=Matrix([(0,-4,0,-1),(0,2,0,0),(0,0,0,0),(4,8,-12,4)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & -4 & 0 & -1\\\\0 & 2 & 0 & 0\\\\0 & 0 & 0 & 0\\\\4 & 8 & -12 & 4\\end{matrix}\\right]\\)\n\n\nPodemos calcular la fórma canónic de Jordan con el método jordan_form.\n\nP,J=A.jordan_form()\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & -2 & 1 & -2\\\\0 & 0 & 0 & 1\\\\1 & 0 & 0 & 0\\\\0 & 4 & 0 & 0\\end{matrix}\\right]\\)\n\n\n\nJ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 2 & 1 & 0\\\\0 & 0 & 2 & 0\\\\0 & 0 & 0 & 2\\end{matrix}\\right]\\)\n\n\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 2 & 1 & 0\\\\0 & 0 & 2 & 0\\\\0 & 0 & 0 & 2\\end{matrix}\\right]\\)\n\n\nHagamos el cálculo “a mano”. Veamos primero cuáles son sus valores propios.\n\nA.eigenvects()\n\n[(0,\n  1,\n  [Matrix([\n   [3],\n   [0],\n   [1],\n   [0]])]),\n (2,\n  3,\n  [Matrix([\n   [-2],\n   [ 1],\n   [ 0],\n   [ 0]]),\n   Matrix([\n   [-1/2],\n   [   0],\n   [   0],\n   [   1]])])]\n\n\nSon el 2 con multiplicidad 3, y el 0 con multiplicidad 1. Vemos que la multiplicidad geométrica de 2 es 2, por lo que la matriz no es diagonalizable.\n\nA2=A-2*eye(4)\nA2\n\n\\(\\displaystyle \\left[\\begin{matrix}-2 & -4 & 0 & -1\\\\0 & 0 & 0 & 0\\\\0 & 0 & -2 & 0\\\\4 & 8 & -12 & 2\\end{matrix}\\right]\\)\n\n\n\nA2.nullspace()\n\n[Matrix([\n [-2],\n [ 1],\n [ 0],\n [ 0]]),\n Matrix([\n [-1/2],\n [   0],\n [   0],\n [   1]])]\n\n\nPor tanto el subespacio propio asociado al 2 tiene dimensión menor que la multiplicidad algebraica de 2 (que es 3). Calculamos \\(\\operatorname{N}(A-2I)^2\\).\n\nV2_2=(A2**2).nullspace()\nV2_2\n\n[Matrix([\n [1],\n [0],\n [0],\n [0]]),\n Matrix([\n [0],\n [1],\n [0],\n [0]]),\n Matrix([\n [0],\n [0],\n [0],\n [1]])]\n\n\nQue ya tiene dimensión tres, igual a la multiplicidad algebraica del autovalor 2. Así el bloque de Jordan correspondiente a este autovalor se formará con una base de \\(\\operatorname{N}(A-2I)^2\\) que contiene a dos vectores de \\(\\operatorname{N}(A-2I)\\).\nEscogemos un vector \\(u\\) de \\(\\operatorname{N}(A-2I)^2\\setminus\\operatorname{N}(A-2I)\\), calculamos \\(Au\\), que estará en \\(\\operatorname{N}(A-2I)\\), y luego tomamos un vector que complete una base de \\(\\operatorname{N}(A-2I)\\). Con estos tres vectores tendremos la caja de Jordan asociada al autovalor 2.\n\nu1=V2_2[0]\nu1\n\n\\(\\displaystyle \\left[\\begin{matrix}1\\\\0\\\\0\\\\0\\end{matrix}\\right]\\)\n\n\n\nu2=A2*u1\nu2\n\n\\(\\displaystyle \\left[\\begin{matrix}-2\\\\0\\\\0\\\\4\\end{matrix}\\right]\\)\n\n\nSeleccionamos un vector de la base de \\(\\ker(A-2I)\\) que sea linealmente independiente con los dos ya calculados.\n\ncand=[v for v in V2_2 if Matrix.hstack(u1,u2,v).rank()==3]\ncand\n\n[Matrix([\n [0],\n [1],\n [0],\n [0]])]\n\n\n\nu3=cand[0]\nu3\n\n\\(\\displaystyle \\left[\\begin{matrix}0\\\\1\\\\0\\\\0\\end{matrix}\\right]\\)\n\n\n\nP2=Matrix.hstack(u1,u2,u3)\nP2\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -2 & 0\\\\0 & 0 & 1\\\\0 & 0 & 0\\\\0 & 4 & 0\\end{matrix}\\right]\\)\n\n\nAhora sólo nos basta completar con la parte de la base correspondiente al autovalor 0.\n\nV0=A.nullspace()\nV0\n\n[Matrix([\n [3],\n [0],\n [1],\n [0]])]\n\n\n\nP=Matrix.hstack(P2,V0[0])\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -2 & 0 & 3\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\\\0 & 4 & 0 & 0\\end{matrix}\\right]\\)\n\n\nComprobemos que la matriz \\(P\\) es una matriz de paso para una forma de Jordan de \\(A\\).\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 0 & 0\\\\1 & 2 & 2 & 0\\\\0 & 0 & 2 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nHagamos ahora el Ejemplo III.5.19 de [I. Ojeda, J. Gago, Métodos matemáticos para la Estadística].",
    "crumbs": [
      "Forma de Jordan"
    ]
  },
  {
    "objectID": "Forma-Jordan.html#ejemplo",
    "href": "Forma-Jordan.html#ejemplo",
    "title": "Forma de Jordan",
    "section": "Ejemplo",
    "text": "Ejemplo\nCalcular la forma de Jordan de la matriz \\[\nA=\\begin{pmatrix}\n1& -1 & 1 &-1\\\\\n-1 & 0 & 1 & -1\\\\\n-1 & 3 & -10&  9\\\\\n0 & 4 & -12 & 11\n\\end{pmatrix}.\n\\]\n\nA=Matrix([(1,-1,1,-1),(-1,0,1,-1),(-1,3,-10,9),(0,4,-12,11)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 1 & -1\\\\-1 & 0 & 1 & -1\\\\-1 & 3 & -10 & 9\\\\0 & 4 & -12 & 11\\end{matrix}\\right]\\)\n\n\n\nP,J = A.jordan_form()\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & -1 & - \\frac{1}{2}\\\\0 & 1 & - \\frac{1}{2} & 1\\\\1 & -3 & \\frac{7}{2} & 0\\\\1 & -4 & 4 & 0\\end{matrix}\\right]\\)\n\n\n\nJ\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 0 & 0\\\\0 & 1 & 1 & 0\\\\0 & 0 & 1 & 1\\\\0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}-1 & 0 & 0 & 0\\\\0 & 1 & 1 & 0\\\\0 & 0 & 1 & 1\\\\0 & 0 & 0 & 1\\end{matrix}\\right]\\)",
    "crumbs": [
      "Forma de Jordan"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html",
    "href": "ALME-sistemas-matrices-determinantes.html",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "",
    "text": "Utilizaremos como ejemplos los proporcionados por L. Merino y E. Santos en el primer bloque de su página de resolución de ejercicios tipo de su libro Álgebra lineal con métodos elementales.",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html#forma-normal-de-hermite-de-una-matriz",
    "href": "ALME-sistemas-matrices-determinantes.html#forma-normal-de-hermite-de-una-matriz",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "Forma normal de Hermite de una matriz",
    "text": "Forma normal de Hermite de una matriz\nPara calcular la forma normal de Hermite por filas, vamos a utilizar la librería sympy. Es interesante echar un vistazo a la documentación que ofrecen sobre matrices y álgebra lineal.\n\nfrom sympy import Matrix\n\nRepasemos cómo podemos hacer operaciones elementales con las filas y columnas de una matriz.\n\nA=Matrix(3,4,range(1,13))\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 3 & 4\\\\5 & 6 & 7 & 8\\\\9 & 10 & 11 & 12\\end{matrix}\\right]\\)\n\n\nRecordemos que los índices en python empiezan en 0. Así la primera fila es\n\nA[0,:]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 3 & 4\\end{matrix}\\right]\\)\n\n\nY la segunda columna\n\nA[:,1]\n\n\\(\\displaystyle \\left[\\begin{matrix}2\\\\6\\\\10\\end{matrix}\\right]\\)\n\n\nPodemos intercambiar columnas con col_swap.\n\nA.col_swap(0,1)\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 1 & 3 & 4\\\\6 & 5 & 7 & 8\\\\10 & 9 & 11 & 12\\end{matrix}\\right]\\)\n\n\nY filas con row_swap.\n\nA.row_swap(0,1)\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}6 & 5 & 7 & 8\\\\2 & 1 & 3 & 4\\\\10 & 9 & 11 & 12\\end{matrix}\\right]\\)\n\n\nPara restarle a la primera fila tres veces la segunda, hacemos\n\nA[0,:]=A[0,:]-3*A[1,:]\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 2 & -2 & -4\\\\2 & 1 & 3 & 4\\\\10 & 9 & 11 & 12\\end{matrix}\\right]\\)\n\n\n\nEjercicio\nCalcular la forma de Hermite por filas y el rango de la matriz: \\[\nA=\n\\left(\\begin{array}{rrrr}\n-2 & -4 &  2  &  2 \\\\\n3 &  6 &  -3 & -3 \\\\\n1 &  2 &  0  &  1\n\\end{array}\\right).\n\\]\nEmpezamos definiendo la matriz del enunciado.\n\nA=Matrix([[-2,-4,2,2],[3,6,-3,-3],[1,2,0,1]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}-2 & -4 & 2 & 2\\\\3 & 6 & -3 & -3\\\\1 & 2 & 0 & 1\\end{matrix}\\right]\\)\n\n\nPara calcular la forma normal de Hermite por filas, usamos rref (row reduced echelon form).\n\nA.rref()\n\n(Matrix([\n [1, 2, 0, 1],\n [0, 0, 1, 2],\n [0, 0, 0, 0]]),\n (0, 2))\n\n\n\n_[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 1\\\\0 & 0 & 1 & 2\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nY el rango lo podemos calcular con rank.\n\nA.rank()\n\n2\n\n\n\n\nEjercicio\nCalcular la forma de Hermite por columnas de la matriz \\[\nA= \\left(\\begin{array}{rrr}\n1 &  2 &  1 \\\\\n2 &  1 &  0 \\\\\n4 &  5 &  2 \\\\\n\\end{array}\\right).\n\\]\n\nA=Matrix([[1,2,1],[2,1,0],[4,5,2]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 1\\\\2 & 1 & 0\\\\4 & 5 & 2\\end{matrix}\\right]\\)\n\n\nPara calcular la forma normal reducida por columnas, calculamos la transpuesta de la forma reducida por filas de la transpuesta de la matriz.\n\nAt=A.transpose()\nrAt,piv =At.rref()\nrAt\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 2\\\\0 & 1 & 1\\\\0 & 0 & 0\\end{matrix}\\right]\\)\n\n\n\nrAt.transpose()\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 0\\\\2 & 1 & 0\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nCalcular la forma de Hermite por filas \\(H\\) de la matriz \\[\nA=\n\\left(\\begin{array}{rrrr}\n-2 & -4 &  2  &  2 \\\\\n3 &  6 &  -3 & -3 \\\\\n1 &  2 &  0  &  1\n\\end{array}\\right)\n\\] así como una matriz regular \\(Q\\) de forma que \\(H=Q\\cdot A\\).\nEmpezamos definiendo la matriz del enunciado, y le añadimos la matriz identidad por columnas. En sympy, la identidad se puede crear con eye.\n\nfrom sympy import eye\n\n\nA=Matrix([[-2,-4,2,2],[3,6,-3,-3],[1,2,0,1]])\nAI=A.row_join(eye(3))\nAI\n\n\\(\\displaystyle \\left[\\begin{matrix}-2 & -4 & 2 & 2 & 1 & 0 & 0\\\\3 & 6 & -3 & -3 & 0 & 1 & 0\\\\1 & 2 & 0 & 1 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nQue también podemos definir con Matrix.hstack (vstack para columnas).\n\nMatrix.hstack(A,eye(3))\n\n\\(\\displaystyle \\left[\\begin{matrix}-2 & -4 & 2 & 2 & 1 & 0 & 0\\\\3 & 6 & -3 & -3 & 0 & 1 & 0\\\\1 & 2 & 0 & 1 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nAhora calculamos su forma normal reducida for filas.\n\nhAI,piv=AI.rref()\nhAI\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 1 & 0 & 0 & 1\\\\0 & 0 & 1 & 2 & 0 & - \\frac{1}{3} & 1\\\\0 & 0 & 0 & 0 & 1 & \\frac{2}{3} & 0\\end{matrix}\\right]\\)\n\n\nLas primeras cuatro filas nos dan la forma normal reducida por filas.\n\nhAI[:,0:4]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 1\\\\0 & 0 & 1 & 2\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nMientras que las restantes nos dan la matriz de paso.\n\nQ=hAI[:,4:7]\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 1\\\\0 & - \\frac{1}{3} & 1\\\\1 & \\frac{2}{3} & 0\\end{matrix}\\right]\\)\n\n\nComprobemos que efectivamente \\(Q A\\) es la forma reducida.\n\nQ*A\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 0 & 1\\\\0 & 0 & 1 & 2\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nCalcular la forma de Hermite por columnas \\(C\\) de la matriz \\[\nA=\n\\left(\\begin{array}{rrrr}\n-2 & -4 &  2 &  2 \\\\\n  3 &  6 & -3 & -3 \\\\\n  1 &  2 &  0 &  1  \\\\\n\\end{array}\\right)\n\\] así como una matriz regular \\(Q\\) de forma que \\(C=A\\cdot Q\\).\nProcedemos como en el ejercicio anterior, pero ahora añadiendo la identidad por columnas debajo de \\(A\\).\n\nA=Matrix([[-2,-4,2,2],[3,6,-3,-3],[1,2,0,1]])\nAI=A.col_join(eye(4))\nAI\n\n\\(\\displaystyle \\left[\\begin{matrix}-2 & -4 & 2 & 2\\\\3 & 6 & -3 & -3\\\\1 & 2 & 0 & 1\\\\1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nCalculamos la forma normal de hermite de AI por columnas (transponiendo, calculando la forma reducida por filas, y volviendo a transponer).\n\nrtAI,piv=AI.transpose().rref()\nrAI=rtAI.transpose()\nrAI\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\- \\frac{3}{2} & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\\\\\frac{1}{2} & -1 & 2 & 4\\\\0 & 1 & -1 & -2\\end{matrix}\\right]\\)\n\n\nAsí la forma reducida por columnas es\n\nH=rAI[0:3,:]\nH\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\- \\frac{3}{2} & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\end{matrix}\\right]\\)\n\n\nY la matriz \\(Q\\) es\n\nQ=rAI[3:8,:]\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\\\\\frac{1}{2} & -1 & 2 & 4\\\\0 & 1 & -1 & -2\\end{matrix}\\right]\\)\n\n\nComprobamos que el resultado es correcto.\n\nA*Q==H\n\nTrue",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html#sistemas-de-ecuaciones-usando-gauss-jordan",
    "href": "ALME-sistemas-matrices-determinantes.html#sistemas-de-ecuaciones-usando-gauss-jordan",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "Sistemas de ecuaciones usando Gauss-Jordan",
    "text": "Sistemas de ecuaciones usando Gauss-Jordan\n\nEjercicio\nDiscutir y resolver, en su caso, el sistema de ecuaciones lineales: \\[\n\\left\\{ \\begin{array}{rcl}\n3x +2y +z&= & 1, \\\\\n2x+3y+z &= & 0,\\\\\n2x+ y+3z &= & 0.\n\\end{array} \\right.\n\\]\nEmpezamos definiendo la matriz de coeficientes y la matriz ampliada.\n\nA=Matrix([[3,2,1],[2,3,1],[2,1,3]])\nb=Matrix([1,0,0])\n\n\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & 2 & 1\\\\2 & 3 & 1\\\\2 & 1 & 3\\end{matrix}\\right]\\)\n\n\n\nb\n\n\\(\\displaystyle \\left[\\begin{matrix}1\\\\0\\\\0\\end{matrix}\\right]\\)\n\n\nPara resolverlo, usamos linsolve.\n\nfrom sympy import linsolve\n\n\nlinsolve((A,b))\n\n\\(\\displaystyle \\left\\{\\left( \\frac{2}{3}, \\  - \\frac{1}{3}, \\  - \\frac{1}{3}\\right)\\right\\}\\)\n\n\nPor lo que la solución es \\(x=2/3\\), \\(y=-1/3\\) y \\(z=-1/3\\).\nUsando la forma normal reducida de la matriz ampliada\n\nAb=A.row_join(b)\nAb\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & 2 & 1 & 1\\\\2 & 3 & 1 & 0\\\\2 & 1 & 3 & 0\\end{matrix}\\right]\\)\n\n\n\nrAb,piv=Ab.rref()\nrAb\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & \\frac{2}{3}\\\\0 & 1 & 0 & - \\frac{1}{3}\\\\0 & 0 & 1 & - \\frac{1}{3}\\end{matrix}\\right]\\)\n\n\nObtenemos que la solución es única: \\(x=2/3\\), \\(y=-1/3\\) y \\(z=-1/3\\).\nEn este caso los rangos de la matriz de coeficientes y de la matriz ampliada coinciden y son máximos.\n\nA.rank()\n\n3\n\n\n\nAb.rank()\n\n3\n\n\n\n\nEjercicio\nDiscutir y resolver, en su caso, el sistema de ecuaciones lineales: \\[\n\\left\\{ \\begin{array}{rcl}\n3x +2y +z&= & 1, \\\\\n2x+3y+z &= & 0,\\\\\nx+ 4y+z &= & 0.\n\\end{array} \\right.\n\\]\n\nA=Matrix([[3,2,1],[2,3,1],[1,4,1]])\nb=Matrix([1,0,0])\n\n\nlinsolve((A,b))\n\n\\(\\displaystyle \\emptyset\\)\n\n\nQue nos indica que el sistema no tiene solución.\nVeamos cómo es la forma reducida por filas de la matriz ampliada.\n\nAb=A.row_join(b)\n\n\nAb.rref()[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & \\frac{1}{5} & 0\\\\0 & 1 & \\frac{1}{5} & 0\\\\0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\nLa incompatibilidad del sistema se aprecia en la última fila, que corresponde a una equación \\(0=1\\).\nPodemos ver la incompatibilidad también estudiando los rangos de la matriz de coeficientes y de la ampliada.\n\nA.rank()\n\n2\n\n\n\nAb.rank()\n\n3\n\n\n\n\nEjercicio\nDiscutir y resolver, en su caso, el sistema de ecuaciones lineales: \\[\n\\left\\{ \\begin{array}{rcl}\n3x +2y +z&= & 1, \\\\\n2x+3y+z &= & 2,\\\\\nx+ 4y+z &= & 3.\n\\end{array} \\right.\n\\]\n\nA=Matrix([[3,2,1],[2,3,1],[1,4,1]])\nb=Matrix([1,2,3])\n\n\nlinsolve((A,b))\n\n\\(\\displaystyle \\left\\{\\left( - \\frac{\\tau_{0}}{5} - \\frac{1}{5}, \\  \\frac{4}{5} - \\frac{\\tau_{0}}{5}, \\  \\tau_{0}\\right)\\right\\}\\)\n\n\nPor lo que el sistema tiene infinitas soluciones. Podemos tomar \\(z\\) como parámatro. Y las soluciones son \\(x=-1/5-1/5z\\), \\(y=4/5-1/5z\\).\n\nAb=A.row_join(b)\n\nVeamos que en este caso los rangos de la matriz de coeficientes y de la matriz ampliada coinciden, pero no son máximos.\n\n(A.rank(),Ab.rank())\n\n(2, 2)",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html#matriz-inversa-usando-operaciones-elementales-por-filas",
    "href": "ALME-sistemas-matrices-determinantes.html#matriz-inversa-usando-operaciones-elementales-por-filas",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "Matriz inversa usando operaciones elementales por filas",
    "text": "Matriz inversa usando operaciones elementales por filas\n\nEjercicio\nEstudiar si la matriz \\[\n\\left(\\begin{array}{rrrr}\n3 &  2 &  3 & 4 \\\\\n3 &  2 &  2 &  3 \\\\\n2 &  1 &  2  & 1 \\\\\n0 & 1 & 1 & 0\n\\end{array}\\right)\n\\] es regular y en tal caso, calcular su matriz inversa.\n\nA=Matrix([[3,2,3,4],[3,2,2,3],[2,1,2,1],[0,1,1,0]])\n\nSi \\(A\\) tiene inversa, la podemos calcular con inv o bien elevando a -1.\n\nA.inv()\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} & - \\frac{1}{2}\\\\- \\frac{1}{2} & \\frac{5}{6} & - \\frac{1}{2} & \\frac{5}{6}\\\\\\frac{1}{2} & - \\frac{5}{6} & \\frac{1}{2} & \\frac{1}{6}\\\\\\frac{1}{2} & - \\frac{1}{6} & - \\frac{1}{2} & - \\frac{1}{6}\\end{matrix}\\right]\\)\n\n\n\nA**(-1)\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} & - \\frac{1}{2}\\\\- \\frac{1}{2} & \\frac{5}{6} & - \\frac{1}{2} & \\frac{5}{6}\\\\\\frac{1}{2} & - \\frac{5}{6} & \\frac{1}{2} & \\frac{1}{6}\\\\\\frac{1}{2} & - \\frac{1}{6} & - \\frac{1}{2} & - \\frac{1}{6}\\end{matrix}\\right]\\)\n\n\nVeamos cómo se puede calcular utilizando la forma normal de Hermite por filas.\n\nAI=A.row_join(eye(4))\nAI\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & 2 & 3 & 4 & 1 & 0 & 0 & 0\\\\3 & 2 & 2 & 3 & 0 & 1 & 0 & 0\\\\2 & 1 & 2 & 1 & 0 & 0 & 1 & 0\\\\0 & 1 & 1 & 0 & 0 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nrAI=AI.rref()[0]\nrAI\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0 & - \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} & - \\frac{1}{2}\\\\0 & 1 & 0 & 0 & - \\frac{1}{2} & \\frac{5}{6} & - \\frac{1}{2} & \\frac{5}{6}\\\\0 & 0 & 1 & 0 & \\frac{1}{2} & - \\frac{5}{6} & \\frac{1}{2} & \\frac{1}{6}\\\\0 & 0 & 0 & 1 & \\frac{1}{2} & - \\frac{1}{6} & - \\frac{1}{2} & - \\frac{1}{6}\\end{matrix}\\right]\\)\n\n\nPor tanto, la inversa es la submatriz formada por las últimas cuatro columnas.\n\nrAI[:,4:9]\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{1}{2} & \\frac{1}{2} & \\frac{1}{2} & - \\frac{1}{2}\\\\- \\frac{1}{2} & \\frac{5}{6} & - \\frac{1}{2} & \\frac{5}{6}\\\\\\frac{1}{2} & - \\frac{5}{6} & \\frac{1}{2} & \\frac{1}{6}\\\\\\frac{1}{2} & - \\frac{1}{6} & - \\frac{1}{2} & - \\frac{1}{6}\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nEstudiar si la matriz \\[\n\\left(\\begin{array}{rrrr}\n1 &  2 &  3 & 4 \\\\\n0 &  1 &   2 &  3 \\\\\n1 &  0 &  2  &  0 \\\\\n1 & 1 & 1 & 1\n\\end{array}\\right)\n\\] es regular y en tal caso, calcular su matriz inversa.\n\nA=Matrix([(1,2,3,4),(0,1,2,3),(1,0,2,0),(1,1,1,1)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 2 & 3 & 4\\\\0 & 1 & 2 & 3\\\\1 & 0 & 2 & 0\\\\1 & 1 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nA.rank()\n\n3\n\n\nLuego no tiene inversa.\nVeamos qué aspecto tiene la forma normal reducida por filas cuando le añadimos la identidad.\n\nA.row_join(eye(4)).rref()[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & - \\frac{4}{3} & 0 & - \\frac{2}{3} & \\frac{1}{3} & \\frac{2}{3}\\\\0 & 1 & 0 & \\frac{5}{3} & 0 & \\frac{1}{3} & - \\frac{2}{3} & \\frac{2}{3}\\\\0 & 0 & 1 & \\frac{2}{3} & 0 & \\frac{1}{3} & \\frac{1}{3} & - \\frac{1}{3}\\\\0 & 0 & 0 & 0 & 1 & -1 & 0 & -1\\end{matrix}\\right]\\)\n\n\nLa última fila muestra que la matriz no puede tener inversa.",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html#matriz-de-paso-entre-dos-matrices-equivalentes-por-filas",
    "href": "ALME-sistemas-matrices-determinantes.html#matriz-de-paso-entre-dos-matrices-equivalentes-por-filas",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "Matriz de paso entre dos matrices equivalentes por filas",
    "text": "Matriz de paso entre dos matrices equivalentes por filas\n\nEjercicio\nEstudiar si las matrices: \\[\nA=\n\\left(\\begin{array}{rrrr}\n  1 &  1 & 1 & 1 \\\\\n  0 &  1 & 1 & 1 \\\\\n  0 &  0 & 1 & 1 \\\\\n\\end{array}\\right)\n; \\;\\;\nB=\n\\left(\\begin{array}{rrrr}\n  1 & 0 &  0 &  0 \\\\\n  1 & 1 &  0 &  0 \\\\\n  1 & 1 &  1 &  1 \\\\\n\\end{array}\\right)\n\\] son equivalentes por filas, y en tal caso determinar una matriz regular \\(Q\\) de forma que \\(A=Q\\cdot B\\).\n\nA=Matrix(3,4, [1,1,1,1,0,1,1,1,0,0,1,1])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & 1\\\\0 & 1 & 1 & 1\\\\0 & 0 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nB=Matrix([(1,0,0,0),(1,1,0,0),(1,1,1,1)])\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\1 & 1 & 0 & 0\\\\1 & 1 & 1 & 1\\end{matrix}\\right]\\)\n\n\nVeamos cómo son sus formas normales de Hermite por filas.\n\nA.rref()[0]\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 1\\end{matrix}\\right]\\)\n\n\n\nB.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 1\\end{matrix}\\right]\\)\n\n\nAhora calculemos la matriz \\(Q\\) del enunciado. Para ello buscamos las matrices \\(Q_A\\) y \\(Q_B\\) tales que \\(Q_A A\\) y \\(Q_B B\\) estén en forma normal reducida por filas.\n\nrAI=A.row_join(eye(3)).rref(pivots=False)\nrAI\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 0 & 1 & -1 & 0\\\\0 & 1 & 0 & 0 & 0 & 1 & -1\\\\0 & 0 & 1 & 1 & 0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nQA=rAI[:,4:]\nQA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & 0\\\\0 & 1 & -1\\\\0 & 0 & 1\\end{matrix}\\right]\\)\n\n\n\nQB=(B.row_join(eye(3)).rref(pivots=False))[:,4:]\nQB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\-1 & 1 & 0\\\\0 & -1 & 1\\end{matrix}\\right]\\)\n\n\nSabemos que \\(Q_A A = Q_B B\\), por lo que la matriz \\(Q\\) que buscamos es \\(Q_A^{-1}Q_B\\).\n\nQ=QA**(-1)*QB\nQ\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 1\\\\-1 & 0 & 1\\\\0 & -1 & 1\\end{matrix}\\right]\\)\n\n\nFinalmente, comprobamos que \\(QB\\) es \\(A\\).\n\nQ*B==A\n\nTrue",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-sistemas-matrices-determinantes.html#determinantes-y-operaciones-elementales",
    "href": "ALME-sistemas-matrices-determinantes.html#determinantes-y-operaciones-elementales",
    "title": "Sistemas de ecuaciones, matrices y determinantes",
    "section": "Determinantes y operaciones elementales",
    "text": "Determinantes y operaciones elementales\n\nEjercicio\nCalcular el determinante \\[\n\\left|\n\\begin{array}{rrrr}\n1 & 1/2 & 1/3 & 1/5\\\\\n-1 & 1/2 & -1/3 & -1/5\\\\\n1 & 1/2 & 4/3 & 1/5\\\\\n2 & 1 & 2/3 & 11/5\\\\\n\\end{array}\n\\right|.\n\\]\n\nA=Matrix([(1,1/2,1/3,1/5),(-1,1/2,-1/3,-1/5),(1,1/2,4/3,1/5),(2,1,2/3,11/5)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0.5 & 0.333333333333333 & 0.2\\\\-1 & 0.5 & -0.333333333333333 & -0.2\\\\1 & 0.5 & 1.33333333333333 & 0.2\\\\2 & 1 & 0.666666666666667 & 2.2\\end{matrix}\\right]\\)\n\n\n\nfrom sympy import Rational,S,Integer\n\n\n1/2\n\n0.5\n\n\n\nInteger(1)/2\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\n\nS(1)/2\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\n\nRational(1/2)\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\n\nRational(\"1/2\")\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\n\nRational(1,2)\n\n\\(\\displaystyle \\frac{1}{2}\\)\n\n\nEn sympy podemos utilizar det para calcular el determinante de una matriz.\n\nA.det()\n\n\\(\\displaystyle 1.8\\)\n\n\n\nu=Integer(1)\nA=Matrix([(u,u/2,u/3,u/5),(-1,u/2,-u/3,-u/5),(u,u/2,u*4/3,u/5),(2,1,u*2/3,u*11/5)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\-1 & \\frac{1}{2} & - \\frac{1}{3} & - \\frac{1}{5}\\\\1 & \\frac{1}{2} & \\frac{4}{3} & \\frac{1}{5}\\\\2 & 1 & \\frac{2}{3} & \\frac{11}{5}\\end{matrix}\\right]\\)\n\n\n\nA.det()\n\n\\(\\displaystyle \\frac{9}{5}\\)\n\n\nHagamos operaciones elementales por filas que no alteren el determinante de forma que lleguemos a una matriz triangular.\n\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\-1 & \\frac{1}{2} & - \\frac{1}{3} & - \\frac{1}{5}\\\\1 & \\frac{1}{2} & \\frac{4}{3} & \\frac{1}{5}\\\\2 & 1 & \\frac{2}{3} & \\frac{11}{5}\\end{matrix}\\right]\\)\n\n\nVamos a conseguir ceros debajo de la primera posición de la primera fila. Para ello empezamos cambiando la segunda fila por la suma de las dos primeras files (lo que no altera el valor del determinante). Hay que tener cuidado con los índices, pues en python empiezan a contar desde cero.\nEl método elementary_row_operation nos permite hacer esto.\n\nA.elementary_row_op(op=\"n-&gt;n+km\",k=1,row=1,row2=0)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\0 & 1 & 0 & 0\\\\1 & \\frac{1}{2} & \\frac{4}{3} & \\frac{1}{5}\\\\2 & 1 & \\frac{2}{3} & \\frac{11}{5}\\end{matrix}\\right]\\)\n\n\nPero si no queremos conservar la matriz original, podemos simplemente sumar las filas correspondientes.\n\nA[1,:]=A[1,:]+A[0,:]\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\0 & 1 & 0 & 0\\\\1 & \\frac{1}{2} & \\frac{4}{3} & \\frac{1}{5}\\\\2 & 1 & \\frac{2}{3} & \\frac{11}{5}\\end{matrix}\\right]\\)\n\n\nAhora cambiamos la tercera por la diferencia de la tercera con la primera.\n\nA[2,:]=A[2,:]-A[0,:]\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\2 & 1 & \\frac{2}{3} & \\frac{11}{5}\\end{matrix}\\right]\\)\n\n\nY la cuarta por la diferencia de la cuarta por dos veces la primera.\n\nA[3,:]=A[3,:]-2*A[0,:]\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & \\frac{1}{2} & \\frac{1}{3} & \\frac{1}{5}\\\\0 & 1 & 0 & 0\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & \\frac{9}{5}\\end{matrix}\\right]\\)\n\n\nLa matriz ya es triangular, con lo que el determinante es el producto de los elementos de la diagonal.\n\nA.diagonal()\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & \\frac{9}{5}\\end{matrix}\\right]\\)\n\n\n\nA.det()\n\n\\(\\displaystyle \\frac{9}{5}\\)\n\n\n\nfrom functools import reduce\n\n\nreduce(lambda x,y:x*y,list(A.diagonal()))\n\n\\(\\displaystyle \\frac{9}{5}\\)\n\n\n\n\nEjercicio\nCalcular el determinante dependiendo de los valores de los parámetros \\(a\\) y \\(b\\). Decidir para qué valores es cero. \\[\n\\left|\n\\begin{array}{rrr}\n1-b & 1-a & a-1\\\\\n-1 & 2-a-b & a\\\\\n-1 & 1-a & a+1-b\\\\\n\\end{array}\n\\right|.\n\\]\nEmpezamos definiendo dos símbolos, a y b\n\nfrom sympy import symbols\n\n\na,b =symbols(\"a,b\")\na,b\n\n(a, b)\n\n\n\nA=Matrix([[1-b,1-a,a-1],[-1,2-a-b,a],[-1,1-a,a+1-b]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 - b & 1 - a & a - 1\\\\-1 & - a - b + 2 & a\\\\-1 & 1 - a & a - b + 1\\end{matrix}\\right]\\)\n\n\n\np=A.det()\np\n\n\\(\\displaystyle - b^{3} + 4 b^{2} - 5 b + 2\\)\n\n\nUsamos factor para factorizar.\n\np.factor()\n\n\\(\\displaystyle - \\left(b - 2\\right) \\left(b - 1\\right)^{2}\\)\n\n\nPor lo que sabemos que el determinante se anula para los valores de \\(b=2\\) y \\(b=1\\), pero no depende de \\(a\\).\nPodríamos usar el comando solve para encontrar las raíces del determinante de la matriz.\n\nfrom sympy import solve\n\n\nsolve(p)\n\n[1, 2]\n\n\nVeamos ahora cómo podemos hacer operaciones elementales por filas y columnas con A tal y como lo hemos definido. Vamos a crear una nueva matriz para no perder la matriz original. No podemos hacer B=A, pues cualquier cambio en B se haría en A (al ser básicamente listas); usamos el método copy.\n\nB=A.copy()\n\n\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 - b & 1 - a & a - 1\\\\-1 & - a - b + 2 & a\\\\-1 & 1 - a & a - b + 1\\end{matrix}\\right]\\)\n\n\nLe restamos a la tercera fila la segunda.\n\nB[2,:]=B[2,:]-B[1,:]\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 - b & 1 - a & a - 1\\\\-1 & - a - b + 2 & a\\\\0 & b - 1 & 1 - b\\end{matrix}\\right]\\)\n\n\nVemos que A queda intacta.\n\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 - b & 1 - a & a - 1\\\\-1 & - a - b + 2 & a\\\\-1 & 1 - a & a - b + 1\\end{matrix}\\right]\\)\n\n\nAhora podemos cambiar la segunda columna por su suma con la tercera.\n\nB[:,1]=B[:,1]+B[:,2]\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 - b & 0 & a - 1\\\\-1 & 2 - b & a\\\\0 & 0 & 1 - b\\end{matrix}\\right]\\)\n\n\nAhora el determinante es much más sencillo de calcular, pues se puede desarrollar por la segunda columna.\n\n\nEjercicio\nDiscutir y resolver en función del parámetro \\(a\\) el sistema de ecuaciones lineales: \\[\n\\left\\{ \\begin{array}{rcl}\nx+ay+az&= & 1, \\\\\nx+2ay+(a+1)z&= &  1, \\\\\n2x+ay+az & = & 2. \\\\\n\\end{array} \\right.\n\\]\n\nA=Matrix([[1,a,a],[1,2*a,a+1],[2,a,a]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a\\\\1 & 2 a & a + 1\\\\2 & a & a\\end{matrix}\\right]\\)\n\n\n\nb=Matrix([1,1,2])\n\n\nAb=A.row_join(b)\nAb\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a & 1\\\\1 & 2 a & a + 1 & 1\\\\2 & a & a & 2\\end{matrix}\\right]\\)\n\n\nHagamos una copia de la matriz extendida y reduzcamos por filas.\n\nB=Ab.copy()\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a & 1\\\\1 & 2 a & a + 1 & 1\\\\2 & a & a & 2\\end{matrix}\\right]\\)\n\n\n\nB[1,:]=B[1,:]-B[0,:]\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a & 1\\\\0 & a & 1 & 0\\\\2 & a & a & 2\\end{matrix}\\right]\\)\n\n\n\nB[2,:]=B[2,:]-2*B[0,:]\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a & 1\\\\0 & a & 1 & 0\\\\0 & - a & - a & 0\\end{matrix}\\right]\\)\n\n\n\nB[2,:]=B[2,:]+B[1,:]\nB\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & a & a & 1\\\\0 & a & 1 & 0\\\\0 & 0 & 1 - a & 0\\end{matrix}\\right]\\)\n\n\nLos valores de \\(a\\) que tenemos que distinguir son 0 y 1, que son precisamente los ceros del determinante de A como polinomio en \\(a\\).\n\np=A.det()\np\n\n\\(\\displaystyle - a^{2} + a\\)\n\n\n\np.factor()\n\n\\(\\displaystyle - a \\left(a - 1\\right)\\)\n\n\n\nsolve(p)\n\n[0, 1]\n\n\nVeamos qué ocurre para \\(a=0\\). Usamos subs (que toma como argumento un diccionario con las substituciones).\n\nAb0=Ab.subs({a:0})\n\n\nAb0.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 1\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nPor lo que en este caso es un sistema compatible indeterminado. Las soluciones son \\(x=1\\), \\(z=0\\) e \\(y\\) puede tomar cualquier valor. Esto también lo podemos conseguir con linsolve.\n\nlinsolve((A.subs({a:0}),b))\n\n\\(\\displaystyle \\left\\{\\left( 1, \\  \\tau_{0}, \\  0\\right)\\right\\}\\)\n\n\nVeamos ahora qué ocurre con \\(a=1\\).\n\nAb1=Ab.subs({a:1})\nAb1\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & 1\\\\1 & 2 & 2 & 1\\\\2 & 1 & 1 & 2\\end{matrix}\\right]\\)\n\n\n\nAb1.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0 & 1\\\\0 & 1 & 1 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\n\nlinsolve((A.subs({a:1}),b))\n\n\\(\\displaystyle \\left\\{\\left( 1, \\  - \\tau_{0}, \\  \\tau_{0}\\right)\\right\\}\\)\n\n\nEn este caso el sistema también es compatible indeterminado: \\(x=1\\), \\(y=-z\\) y \\(z\\) puede tomar cualquier valor.\nPara el resto de valores de \\(a\\), el sistema es compatible determinado, pues el rango de \\(A\\) y el de la matriz ampliada es el mismo y es máximo.\nPor lo que la solución es \\(x=1\\), \\(y=z=0\\).\n\nlinsolve((A,b))\n\n\\(\\displaystyle \\left\\{\\left( 1, \\  0, \\  0\\right)\\right\\}\\)\n\n\n\n\nEjercicio\nDiscutir, en función de los valores del parámetro \\(a\\), el sistema \\[\n\\left\\{\n\\begin{array}{rrrl}\nx&+y& +z&=a,\\\\\nx&+ay& + a^2z&=a,\\\\\nx&+a^2y& +az&=a,\\\\\nx&+y& +az&=0.\\\\\n\\end{array}\n\\right.\n\\]\n\nA=Matrix([[1,1,1],[1,a,a**2],[1,a**2,a],[1,1,a]])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1\\\\1 & a & a^{2}\\\\1 & a^{2} & a\\\\1 & 1 & a\\end{matrix}\\right]\\)\n\n\n\nb=Matrix([a,a,a,0])\n\n\nAb=A.row_join(b)\nAb\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 1 & a\\\\1 & a & a^{2} & a\\\\1 & a^{2} & a & a\\\\1 & 1 & a & 0\\end{matrix}\\right]\\)\n\n\nObservemos que la matriz ampliada tiene cuatro columnas y cuatro filas, mientras que A tiene sólo tres columnas. Esto quiere decir que como mucho el rango de A es tres, mientras que si el determinante de la matriz ampliada es no nulo, entonces su rango sería cuatro, dando lugar a un sistema incompatible. Veamos pues para qué valores de \\(a\\) se anula el determinante de Ab.\n\np=Ab.det()\np.factor()\n\n\\(\\displaystyle a^{2} \\left(a - 1\\right)^{2} \\left(a + 2\\right)\\)\n\n\nPor tanto si \\(a\\not\\in \\{-2,0,1\\}\\) el sistema será incompatible. Veamos qué ocurre para el resto de los casos.\nPara \\(a=-2\\), obtenemos un sistema compatible determinado, y \\(x=y=z=-2/3\\).\nPara \\(a=0\\), también (\\(x=y=z=0\\)).\nPor último, para \\(a=1\\), obtenemos un sistema incompatible.\n\n[linsolve((A.subs({a:i}),b.subs({a:i}))) for i in [-2,0,1]]\n\n[{(-2/3, -2/3, -2/3)}, {(0, 0, 0)}, EmptySet]",
    "crumbs": [
      "Sistemas de ecuaciones, matrices, determinantes"
    ]
  },
  {
    "objectID": "ALME-aplicaciones-lineales.html",
    "href": "ALME-aplicaciones-lineales.html",
    "title": "Aplicaciones lineales",
    "section": "",
    "text": "En este documento ilustraremos cómo usar Python para resolver los problemas tipo propuestos por L. Merino y E. Santos en página de resolución de ejercicios tipo correspondientes al bloque “Aplicaciones Lineales”.\n\nEjercicio\nSe considera la aplicación lineal \\(D: \\mathcal{P}_3(\\mathbb{R}) \\longrightarrow \\mathcal{P}_2(\\mathbb{R})\\) que a cada polinomio de \\(\\mathcal{P}_3(\\mathbb{R})\\) le asigna su derivada: \\(D(p(x))=p'(x)\\). Determinar la matriz asociada a \\(D\\) respecto de la base estándar \\(B=\\{ 1, x, x^2, x^3\\}\\).\nNuestra matriz tiene por columnas las coordenadas de las imágenes de los vectores de la base: \\[\n\\begin{array}{lcccl}\nD(1)&=   & 0 &=   & (0,0,0,0)_B, \\\\\nD(x) &=  & 1 &=   & (1,0,0,0)_B, \\\\\nD(x^2)&= & 2x &=  & (0,2,0,0)_B, \\\\\nD(x^3)&= & 3x^2& =&(0,0,3,0)_B.\n\\end{array}\n\\]\n\nfrom sympy import Symbol, Matrix, eye\n\n\nA=Matrix([(0,0,0,0),(1,0,0,0),(0,2,0,0),(0,0,3,0)]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 1 & 0 & 0\\\\0 & 0 & 2 & 0\\\\0 & 0 & 0 & 3\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nDe una aplicación lineal \\(f:\\mathbb{R}^3 \\longrightarrow \\mathbb{R}^2\\) se sabe que \\[\n\\begin{array}{l}\nf(1,0,0)=(1,0),\\\\\nf(0,1,0)= (1,1), \\\\\nf(0,0,1)=(0,-1).\n\\end{array}\n\\]\nDeterminar la matriz asociada a \\(f\\) respecto de las respectivas bases canónicas de \\(\\mathbb{R}^3\\) y \\(\\mathbb{R}^2\\) y calcular \\(f(1,2,1)\\).\nLa matriz asociada a \\(f\\) respecto de las bases canónicas es\n\nA=Matrix([[1,0],[1,1],[0,-1]]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 0\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nLa imagen de \\((1,2,1)\\) se obtiene multiplicando A por \\((1,2,1)^t\\).\n\nA*Matrix([1,2,1])\n\n\\(\\displaystyle \\left[\\begin{matrix}3\\\\1\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nSe considera la aplicación lineal \\(f:\\mathbb{R}^3 \\longrightarrow \\mathbb{R}^3\\) definida por \\(f(x,y,z)=(x+y,x+z, y-z)\\). Obtener unas ecuaciones cartesianas de \\(\\operatorname{Im}(f)\\).\n\n[0,1]*5\n\n[0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n\n\n\nf=lambda x,y,z: Matrix([x+y,x+z,y-z])\nA=Matrix(3,3,[0]*9)\nA[:,0]=f(1,0,0)\nA[:,1]=f(0,1,0)\nA[:,2]=f(0,0,1)\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 1 & 0\\\\1 & 0 & 1\\\\0 & 1 & -1\\end{matrix}\\right]\\)\n\n\nPodemos usar la forma normal por columnas de esa matriz para calcular una base de \\(\\operatorname{Im}(f)\\).\n\nA.T.rref(pivots=False)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 1\\\\0 & 1 & -1\\\\0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nA partir de aquí podríamos calcular las ecuaciones cartesianas. Nosotros vamos a utilizar nuestra función gensec definida en el bloc ALME-espacios-vectoriales.ipynb.\n\ndef gensec(A):\n    \"\"\"\n    A es una matriz cuyas filas son los generadores o los coeficientes del subespacio\n    La salida son las ecuaciones implícitas o los generadores (por filas)\n    \"\"\"\n    c=A.cols # número de columnas de A\n    f=A.rows # número de filas\n    r=A.rank() # rango\n    rtAI=A.T.row_join(eye(c)).rref(pivots=False) # añadimos la identidad calculamor forma reducida por columnas\n    ecs=rtAI[r:,f:]# nos quedamos con la parte que corresponde a ceros (ecuaciones o generadores según la entrada)\n    return ecs\n\n\ngensec(A.T)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & -1\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nSe considera la aplicación lineal \\(f:\\mathbb{R}^3 \\longrightarrow \\mathbb{R}^3\\) definida por \\(f(x,y,z)=(x+y,x+z, y-z)\\), obtener una base de \\(\\operatorname{N}(f)\\).\nPodemos usar de nuevo gensec, pues unas ecuaciones del núcleo son \\[\n\\left\\{ \\begin{array}{ccc}\nx+y & = & 0, \\\\\nx+z& = & 0, \\\\\ny-z& = & 0.\n\\end{array}\\right.\n\\]\n\ngensec(A)\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & -1 & -1\\end{matrix}\\right]\\)\n\n\nPodemos también usar el método nullspace, que calcula el núcleo de una de una aplicación lineal.\n\nA.nullspace()\n\n[Matrix([\n [-1],\n [ 1],\n [ 1]])]\n\n\nPor tanto, una base para el núcleo de \\(F\\) es \\(\\{(-1,1,1)\\}\\).\n\n\nEjercicio\nSe considera la aplicación lineal \\(D: \\mathcal{P}_3(\\mathbb{R}) \\longrightarrow \\mathcal{P}_3(\\mathbb{R})\\) que a cada polinomio de \\(\\mathcal{P}_3(\\mathbb{R})\\) le asigna su derivada: \\(D(p(x))=p'(x)\\). Determinar la matriz asociada a \\(D\\) respecto de la base \\(\\bar{B}=\\{ 1+x^2, x+x^3, 1+x^3, x^3\\}\\).\nRecordemos que la matriz asociada a la base estándar es\n\nA=Matrix([(0,0,0,0),(1,0,0,0),(0,2,0,0),(0,0,3,0)]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 1 & 0 & 0\\\\0 & 0 & 2 & 0\\\\0 & 0 & 0 & 3\\\\0 & 0 & 0 & 0\\end{matrix}\\right]\\)\n\n\nLa matriz de cambio de \\(\\overline{B}\\) a \\(B\\) se obtiene poniendo las coordenadas de los vectores de \\(\\overline{B}\\) respecto de \\(B\\) en una matriz por columnas.\n\nP=Matrix([(1,0,1,0),(0,1,0,1),(1,0,0,1),(0,0,0,1)]).T\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 1 & 0\\\\0 & 1 & 0 & 0\\\\1 & 0 & 0 & 0\\\\0 & 1 & 1 & 1\\end{matrix}\\right]\\)\n\n\nLa matriz de cambio de base de \\(B\\) a \\(\\overline{B}\\) es \\(P^{-1}\\).\n\nP.inv()\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 0 & 1 & 0\\\\0 & 1 & 0 & 0\\\\1 & 0 & -1 & 0\\\\-1 & -1 & 1 & 1\\end{matrix}\\right]\\)\n\n\nAsí si partimos de coordenadas en \\(\\overline{B}\\) y queremos aplicar \\(f\\) para terminar obteniendo coordenadas respectdo de \\(\\overline{B}\\), lo primero que tenemos que hacer es traducir esas coordenadas a \\(B\\), aplicar \\(f\\), que devuelve su salida en coordenadas respecto a \\(B\\), y finalmente convertir esas coordenadas a \\(\\overline{B}\\). Por tanto, la matriz buscada es \\(P^{-1}AP\\).\n\nP.inv()*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & 3 & 3 & 3\\\\2 & 0 & 0 & 0\\\\0 & -2 & -3 & -3\\\\-2 & 2 & 3 & 3\\end{matrix}\\right]\\)\n\n\n\n\nEjercicio\nDe una aplicación lineal \\(f:\\mathbb{R}^3 \\longrightarrow \\mathbb{R}^4\\) se sabe que \\[\n\\begin{array}{l}\nf(1,2,1)=(1,0,1,0),\\\\\nf(2,1,2)= (0,1,0,1), \\\\\nf(1,0,0)=(0,0,0,0).\n\\end{array}\n\\] Determinar la matriz asociada a \\(f\\) respecto de las respectivas bases canónicas de \\(\\mathbb{R}^3\\) y \\(\\mathbb{R}^4\\) y determinar \\(f(3,1,1)\\).\nComprobemos que \\(\\overline{B}=\\{(1,2,1),(2,1,2),(1,0,0)\\}\\) es una base.\n\nP=Matrix([(1,2,1),(2,1,2),(1,0,0)]).T\nP.rank()\n\n3\n\n\nTenemos así que \\(\\overline{B}\\) es una base, y \\(P\\) pasa de \\(\\overline{B}\\) a la base canónica. Además, la matriz de \\(f\\) respecto de \\(\\overline{B}\\) y la base canónica de \\(\\mathbb{R}^4\\) es\n\nA=Matrix([(1,0,1,0),(0,1,0,1),(0,0,0,0)]).T\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 0\\\\1 & 0 & 0\\\\0 & 1 & 0\\end{matrix}\\right]\\)\n\n\nPara calcular la matriz con respecto a las bases canónicas, primero traducimos coordenadas de la base canónica a \\(\\overline{B}\\) y luego aplicamos \\(f\\) (cuya salida ya es en coordenadas respecto de la base canónica). Por tanto, la matriz asociada es \\(A*P^{-1}\\).\n\nA*P.inv()\n\n\\(\\displaystyle \\left[\\begin{matrix}0 & \\frac{2}{3} & - \\frac{1}{3}\\\\0 & - \\frac{1}{3} & \\frac{2}{3}\\\\0 & \\frac{2}{3} & - \\frac{1}{3}\\\\0 & - \\frac{1}{3} & \\frac{2}{3}\\end{matrix}\\right]\\)\n\n\nLa imagen de \\((3,1,1)\\) es\n\nA*P.inv()*Matrix([3,1,1])\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{1}{3}\\\\\\frac{1}{3}\\\\\\frac{1}{3}\\\\\\frac{1}{3}\\end{matrix}\\right]\\)",
    "crumbs": [
      "Aplicaciones lineales"
    ]
  },
  {
    "objectID": "Diagonalizacion-simetricas-semejanza-ortogonal.html",
    "href": "Diagonalizacion-simetricas-semejanza-ortogonal.html",
    "title": "Diagonalización de matrices simétricas por semejanza ortogonal",
    "section": "",
    "text": "Para ilustrar cómo diagonalizar matrices simétricas por semejanza ortogonal, vamos a usar el Ejemplo 9 (Capítulo IV) de [L. Merino, E. Santos Álgebra Lineal con Métodos Elementales].",
    "crumbs": [
      "Diagonalización por semejanza ortogonal"
    ]
  },
  {
    "objectID": "Diagonalizacion-simetricas-semejanza-ortogonal.html#ejemplo",
    "href": "Diagonalizacion-simetricas-semejanza-ortogonal.html#ejemplo",
    "title": "Diagonalización de matrices simétricas por semejanza ortogonal",
    "section": "Ejemplo",
    "text": "Ejemplo\nEncuentra una matriz ortogonal \\(P\\) tal que \\(P^tAP\\) sea diagonal, con \\[\nA=\\begin{pmatrix}3 & 1 & 1\\\\\n1 & 3 & 1\\\\\n1 & 1 & 3\n\\end{pmatrix}.\n\\]\n\nfrom sympy import Matrix,eye,GramSchmidt\n\n\nA=Matrix([(3,1,1),(1,3,1),(1,1,3)])\nA\n\n\\(\\displaystyle \\left[\\begin{matrix}3 & 1 & 1\\\\1 & 3 & 1\\\\1 & 1 & 3\\end{matrix}\\right]\\)\n\n\nVamos a calcular los autovalores y los subespacios propios asociados.\n\nA.charpoly().all_roots()\n\n[2, 2, 5]\n\n\n\nV2=(A-2*eye(3)).nullspace()\nV2\n\n[Matrix([\n [-1],\n [ 1],\n [ 0]]),\n Matrix([\n [-1],\n [ 0],\n [ 1]])]\n\n\nUsamos GramSchmidt para calcular una base ortonormal de V2.\n\nV2o=GramSchmidt(V2,True)\nV2o\n\n[Matrix([\n [-sqrt(2)/2],\n [ sqrt(2)/2],\n [         0]]),\n Matrix([\n [-sqrt(6)/6],\n [-sqrt(6)/6],\n [ sqrt(6)/3]])]\n\n\nAhora procedemos con el valor propio 5.\n\nV5=(A-5*eye(3)).nullspace()\nV5o=GramSchmidt(V5,True)\nV5o\n\n[Matrix([\n [sqrt(3)/3],\n [sqrt(3)/3],\n [sqrt(3)/3]])]\n\n\nJuntamos las bases y creamos la matrix de paso P.\n\nP=Matrix.hstack(*(V2o+V5o))\nP\n\n\\(\\displaystyle \\left[\\begin{matrix}- \\frac{\\sqrt{2}}{2} & - \\frac{\\sqrt{6}}{6} & \\frac{\\sqrt{3}}{3}\\\\\\frac{\\sqrt{2}}{2} & - \\frac{\\sqrt{6}}{6} & \\frac{\\sqrt{3}}{3}\\\\0 & \\frac{\\sqrt{6}}{3} & \\frac{\\sqrt{3}}{3}\\end{matrix}\\right]\\)\n\n\n\nP.T*A*P\n\n\\(\\displaystyle \\left[\\begin{matrix}2 & 0 & 0\\\\0 & 2 & 0\\\\0 & 0 & 5\\end{matrix}\\right]\\)",
    "crumbs": [
      "Diagonalización por semejanza ortogonal"
    ]
  }
]